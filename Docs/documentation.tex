%% Copyright (C) 2005, Carnegie Mellon University and others.
%%
%% The first version of this file was contributed to the Ipopt project
%% on Aug 1, 2005, by Yoshiaki Kawajiri
%%                    Department of Chemical Engineering
%%                    Carnegie Mellon University
%%                    Pittsburgh, PA 15213
%%
%% Since then, the content of this file has been updated significantly by
%%     Carl Laird and Andreas Waechter        IBM
%%
%%
%% $Id$
%%
\documentclass[10pt]{article}
\setlength{\textwidth}{6.3in}       % Text width
\setlength{\textheight}{9.4in}      % Text height
\setlength{\oddsidemargin}{0.1in}     % Left margin for even-numbered pages
\setlength{\evensidemargin}{0.1in}    % Left margin for odd-numbered pages
\setlength{\topmargin}{-0.5in}         % Top margin
\renewcommand{\baselinestretch}{1.1}
\usepackage{amsfonts}
\usepackage{amsmath}

\newcommand{\RR}{{\mathbb{R}}}
\newcommand{\Ipopt}{{\sc Ipopt}}


\begin{document}
\title{Introduction to \Ipopt:\\
A tutorial for downloading, installing, and using \Ipopt.}

\author{Revision number of this document: $Revision$}

%\date{\today}
\maketitle

\begin{abstract}
  This document is a guide to using \Ipopt\ 3.0 (the new C++ version
  of \Ipopt).  It includes instructions on how to obtain and compile
  \Ipopt, an description of the interface, user options, etc.,, as
  well as a tutorial on how to solve a nonlinear optimization problem
  with \Ipopt.

  The initial version of this document was created by
  Yoshiaki Kawajir\footnote{Department of Chemical Engineering,
    Carnegie Mellon University, Pittsburgh PA} as a course project for
  \textit{47852 Open Source Software for Optimization}, taught by
  Prof. Fran\c cois Margot at Tepper School of Business, Carnegie
  Mellon University.  The current version is maintained by Carl
  Laird\footnote{Department of Chemical Engineering, Carnegie Mellon
    University, Pittsburgh PA} and Andreas
  W\"achter\footnote{Department of Mathematical Sciences, IBM T.J.\
    Watson Research Center, Yorktown Heights, NY}.
\end{abstract}

\tableofcontents

\vspace{\baselineskip}
\begin{small}
\noindent
The following names used in this document are trademarks or registered
trademarks: AMPL, Intel, Microsoft, Visual Studio C++, Visual Studio
C++ .NET
\end{small}

\section{Introduction}
\Ipopt\ (\underline{I}nterior \underline{P}oint \underline{Opt}imizer,
pronounced ``I--P--Opt'') is an open source software package for
large-scale nonlinear optimization. It can be used to solve general
nonlinear programming problems of the form
%\begin{subequations}\label{NLP}
\begin{eqnarray}
\min_{x\in\RR^n} &&f(x) \label{eq:obj} \\
\mbox{s.t.} \;  &&g^L \leq g(x) \leq g^U \\
                &&x^L \leq x \leq x^U, \label{eq:bounds}
\end{eqnarray}
%\end{subequations}
where $x \in \RR^n$ are the optimization variables (possibly with
lower and upper bounds, $x^L\in(\RR\cup\{-\infty\})^n$ and
$x^U\in(\RR\cup\{+\infty\})^n$), $f:\RR^n\longrightarrow\RR$ is the
objective function, and $g:\RR^n\longrightarrow \RR^m$ are the general
nonlinear constraints.  The functions $f(x)$ and $g(x)$ can be linear
or nonlinear and convex or non-convex (but should be twice
continuously differentiable). The constraints, $g(x)$, have lower and
upper bounds, $g^L\in(\RR\cup\{-\infty\})^n$ and
$g^U\in(\RR\cup\{+\infty\})^m$. Note that equality constraints of the
form $g_i(x)=\bar g_i$ can be specified by setting
$g^L_{i}=g^U_{i}=\bar g_i$.

\subsection{Mathematical Background}
\Ipopt\ implements an interior point line search filter method that
aims to find a local solution of (\ref{eq:obj}-\ref{eq:bounds}).  The
mathematical details of the algorithm can be found in several
publications
\cite{NocWaeWal:adaptive,WaechterPhD,WaeBie:IpoptImpl,WaeBie05:filterglobal,WaeBie05:filterlocal}.

\subsection{Availability}
The \Ipopt\ package is available from COIN-OR
(\texttt{www.coin-or.org}) under the CPL (Common Public License)
open-source license and includes the source code for \Ipopt.  This
means, it is available free of charge, also for commercial purposes.
However, if you give away software including \Ipopt\ code (in source
code or binary form) and you made changes to the \Ipopt\ source code,
you are required to publicly and clearly indicate which modifications
you made.  After all, the goal of open source software is the
continuous development and improvement of software.  For details,
please refer to the Common Public License.

Also, if you are using \Ipopt\ to obtain results for a publication, we
politely ask you to point out in your paper that you used \Ipopt, and
to cite the publication \cite{WaeBie:IpoptImpl}.  Writing high-quality
numerical software takes a lot of time and effort, and does usually
not translate into a high number of publications, therefore we believe
this request is only fair :).

\subsection{Prerequisites}
In order to build \Ipopt, some third party components are required:
\begin{itemize}
\item BLAS (Basic Linear Algebra Subroutines).  Many vendors of
  compilers and operating systems provide precompiled and optimized
  libraries for these dense linear algebra subroutines.  But you can
  also get the source code from {\tt www.netlib.org} and have the
  \Ipopt\ distribution compile it automatically.
\item A sparse symmetric indefinite linear solver. The \Ipopt\ needs
  to obtain the solution of sparse, symmetric, indefinite linear
  systems, and for this it relies on third-party code.  Currently,
  your only option is the solver MA27 from the Harwell Subroutine
  Library (see {\tt http://www.cse.clrc.ac.uk/nag/hsl/}).  We are
  working on interfaces for \Ipopt\ with some other linear solvers.

  Furthermore, we also make use a subroutine for scaling the linear
  systems arising in \Ipopt, using the HSL routine MC19.  It is not
  required to have MC19 to compile \Ipopt; if this routine is missing,
  the scaling is never performed.
\item ASL (AMPL Solver Library).  The source code available is at {\tt
    www.netlib.org}, and the \Ipopt\ makefiles will automatically
  compile it for you if you put the source code into a designated
  space.  NOTE: This is only required if you want to use \Ipopt\ from
  AMPL and want to compile the \Ipopt\ AMPL solver executable.
  solver
\end{itemize}
For more information on third-party components and how to obtain them,
see Section~\ref{ExternalCode}.

Since the \Ipopt\ code is written in C++, you will need a C++ compiler
to build the \Ipopt\ library.  We tried very hard to write the code as
platform and compiler independent as possible.

In addition, since MA27 is currently the only linear solver interfaced
with \Ipopt, and MA27 is written in Fortran, you will also need a
Fortran compiler in order to compile MA27.  However, we believe that
it is possible to use the Fortran-to-C compiler {\tt f2c} from {\tt
  www.netlib.org} to convert the MA27 source code to C, and then
compile the resulting C files with a C compiler and create a library
containing the required HSL code.  But so far we haven't tested this,
and currently the configuration script for \Ipopt\ looks for a Fortran
compiler.

\subsection{How to use \Ipopt}
If desired, the \Ipopt\ distribution generates an executable for the
modeling environment AMPL. As well, you can link your problem
statement with \Ipopt\ using interfaces for Fortran, C, or C++.
\Ipopt\ can be used with most Linux/Unix environments, and on Windows
using Visual Studio .NET or Cygwin.  Below in
Section~\ref{sec:tutorial-example} this document demonstrate how to
solve problems using \Ipopt. This includes installation and
compilation of \Ipopt\ for use with AMPL as well as linking with your
own code.

Finally, the \Ipopt\ distribution includes an interface for {\tt CUTEr}
(see {\tt http://cuter.rl.ac.uk/cuter-www/}), if you want to use
\Ipopt\ to solve problems modeled in SIF.

The old version of \Ipopt\ has been interface with Matlab, and is also
available from NEOS, and the new version will be available through
similar means in the future.  Please check the \Ipopt\ homepage for
updates.

\subsection{More Information}
More and up-to-date information can be found at the \Ipopt\ homepage,

\begin{center}
\texttt{http://projects.coin-or.org/Ipopt}.
\end{center}

Here, you can find FAQs, some (hopefully useful) hints, a bug report
system etc.

\Ipopt\ is an open source project, and we encourage people to
contribute code (such as interfaces to appropriate linear solvers,
modeling environments, or even algorithmic features).  If you are
interested in contributing code, please have a look at the COIN page
{\tt http://www.coin-or.org/contributions.html}, and contact the
\Ipopt\ project leader.

There is also a mailing list for \Ipopt, {\tt
  http://list.coin-or.org/mailman/listinfo/coin-ipopt}, where you can
subscribe to get notified of updates, and to ask general questions
regarding installation and usage. (You might want to look at the
archives before posting a question.)

We try to answer questions posted to the mailing list in a reasonable
manner.  Please understand that we cannot answer all questions in
detail, and because of time constraints, we may not be able to help
you model and debug your particular optimization problem.  However, if
you have a challenging optimization problem and are interested in
consulting services by IBM Research, please contact the \Ipopt\
project leader, Andreas W\"achter.

\subsection{History of \Ipopt}
The original \Ipopt\ (Fortran version) was a product of the dissertation
research of Andreas W\"achter \cite{WaechterPhD}, under Lorenz
T. Biegler at the Chemical Engineering Department at Carnegie Mellon
University. The code was made open source and distributed by the
COIN-OR initiative, which is now a non-profit corporation.  \Ipopt\ has
been actively developed under COIN-OR since 2002.

To continue natural extension of the code and allow easy addition of
new features, IBM Research decided to invest in an open source
re-write of \Ipopt\ in C++.  The new C++ version of the \Ipopt\
optimization code (\Ipopt\ 3.0 and beyond) is currently developed at IBM
Research and remains part of the COIN-OR initiative. Future
development on the Fortran version will cease with the exception of
occasional bug fix releases.

\section{Installing \Ipopt}\label{Installing}

The following sections describe the installation procedures on
UNIX/Linux systems.  For installation instructions on Windows
see Section~\ref{WindowsInstall}.

\subsection{Getting the \Ipopt\ Code}
\Ipopt\ is available from the COIN-OR subversion repository. You can
either download the code using \texttt{svn} (the
\textit{subversion}\footnote{see
  \texttt{http://subversion.tigris.org/}} client similar to CVS) or
simply retrieve a tarball (compressed archive file).  While the
tarball is an easy method to retrieve the code, using the
\textit{subversion} system allows users the benefits of the version
control system, including easy updates and revision control.

\subsubsection{Getting the \Ipopt\ code via subversion}

Of course, the \textit{subversion} client must be installed on your
system if you want to obtain the code this way (the executable it
called \texttt{svn}); it is already installed by default for many
recent Linux distributions.  Information about \textit{subversion} and
how to download it can be found at
\texttt{http://subversion.tigris.org/}.\\

To obtain the \Ipopt\ source code via subversion, follow the steps
below:
\begin{enumerate}
\item{Create a directory to store the code}\\
{\tt \$ mkdir Ipopt}\\ 
Note the {\tt \$} indicates the command line
prompt, do not type {\tt \$}, only the text following it.
\item{Download the code to the new directory}\\
{\tt \$ cd Ipopt\\
\$ svn co https://www.coin-or.org/svn/Ipopt/trunk}
\item Change into the root directory of the \Ipopt\ distribution\\
{\tt \$ cd trunk}
\end{enumerate}

In the following, ``\texttt{\$IPOPTDIR}'' will refer to the directory in
which you are right now (output of \texttt{pwd}).

\subsubsection{Getting the \Ipopt\ code as a tarball}

To use the tarball, follow the steps below:
\begin{enumerate}
\item Download the latest tarball from
\texttt{http://www.coin-or.org/Tarballs}.  The file you should look
for has the form \texttt{ipopt-3.x.x.tar.gz} (where
``\texttt{3.x.x.}'' is the version number).  Put this file in a
directory under which you want to put the \Ipopt\ installation.
\item Issue the following commands to unpack the archive file: \\
\texttt{\$ gunzip ipopt-3.x.x.tar.gz} \\
\texttt{\$ tar xvf ipopt-3.x.x.tar} \\
Note the {\tt \$} indicates the command line
prompt, do not type {\tt \$}, only the text following it.
\item Change into the root directory of the \Ipopt\ distribution\\
{\tt \$ cd ipopt-3.x.x}
\end{enumerate}

In the following, ``\texttt{\$IPOPTDIR}'' will refer to the directory in
which you are right now (output of \texttt{pwd}).

\subsection{Download External Code}\label{ExternalCode}
\Ipopt\ uses a few external packages that are not included in the
\Ipopt\ source code distribution, namely ASL (the AMPL Solver
Library), BLAS, and some sparse linear algebra routines from the
Harwell Subroutine Library.

Since those packages are released under different licenses than
\Ipopt, we cannot distribute that code together with the \Ipopt\
packages and have to ask you to go through the hassle of obtaining it
yourself (even though we tried to make it as easy for you as we
could).  Keep in mind that it is still your responsibility to ensure
that your downloading and usage if the third party components conforms
with their licenses.

Note that you only need to obtain the ASL if you intend to use \Ipopt\
from AMPL.  It is not required if you want to specify your
optimization problem in a programming language (C++, C, or Fortran).

\subsubsection{Download BLAS and ASL}
If you have the download utility \texttt{wget} installed on your
system, retrieving ASL, and BLAS is straightforward using scripts
included with the ipopt distribution. These scripts download the
required files from the Netlib Repository (\texttt{www.netlib.org}).\\

\noindent
{\tt \$ cd \$IPOPTDIR/Extern/blas}\\
{\tt \$ ./get.blas}\\
{\tt \$ cd ../ASL}\\
{\tt \$ ./get.asl}\\

\noindent
If you don't have \texttt{wget} installed on your system, please read
the \texttt{INSTALL.*} files in the \texttt{\$IPOPTDIR/Extern/blas}
and \texttt{\$IPOPTDIR/Extern/ASL} directories for alternative
instructions.

\subsubsection{Download HSL Subroutines}
In addition to the \Ipopt\ source code, two additional subroutines have
to be downloaded from the Harwell Subroutine Library (HSL).  The
required routines are freely available for non-commercial, academic
use, but it is your responsibility to investigate the licensing of all
third party code.
\begin{enumerate}
\item Go to {\tt http://hsl.rl.ac.uk/archive/hslarchive.html}
\item Follow the instruction on the website, read the license, and
  submit the registration form.
\item Go to \textit{HSL Archive Programs}, and find the package list.
\item In your browser window, click on \textit{MA27}.
\item Make sure that \textit{Double precision:} is checked. 
  Click \textit{Download package (comments removed)}
\item Save the file as {\tt ma27ad.f} in {\tt \$IPOPTDIR/Extern/HSL/}\\
  Note: Some browsers append a file extension ({\tt .txt}) when you save
  the file, so you may have to rename it.
\item Go back to the package list using the back button of your browser.
\item In your browser window, click on \textit{MC19}.
\item Make sure \textit{Double precision:} is checked. Click 
  \textit{Download package (comments removed)}
\item Save the file as {\tt mc19ad.f} in {\tt
    \$IPOPTDIR/Extern/HSL/}\\
  Note: Some browsers append a file extension ({\tt .txt}) when you save
  the file, so you may have to rename it.
\end{enumerate}

Note: Whereas currently obtaining MA27 is essential for using \Ipopt,
MC19 could be omitted (with the consequence that you cannot use this
method for scaling the linear systems arising inside the \Ipopt\
algorithm).

\subsection{Compiling and Installing \Ipopt} \label{sec.comp_and_inst}

\Ipopt\ can be easily compiled and installed with the usual {\tt
  configure}, {\tt make}, {\tt make install} commands.  Below are the
basic steps that should work on most systems.  For special
compilations and some for troubleshooting see
Appendix~\ref{ExpertInstall} and consult the \Ipopt\ homepage before
submitting a ticket or sending a message to the mailing list.
\begin{enumerate}
\item Go to the main directory of \Ipopt:\\
  {\tt \$ cd \$IPOPTDIR} 
\item Run the configure script\\
  {\tt \$ ./configure}

  If the last output line of the script reads ``\texttt{configure:
    Configuration successful}'' then everything worked fine.
  Otherwise, look at the screen output, have a look at the
  \texttt{config.log} output file and/or consult
  Appendix~\ref{ExpertInstall}.

  The default configure (without any options) is sufficient for most
  users. If you want to see the configure options, consult
  Appendix~\ref{ExpertInstall}.
\item Build the code \\
{\tt \$ make}
\item Install \Ipopt \\
  {\tt \$ make install}\\
  This installs
  \begin{itemize}
  \item the \Ipopt\ AMPL solver executable (if ASL source was
    downloaded) in \texttt{\$IPOPTDIR/bin},
  \item the \Ipopt\ library (\texttt{libipopt.a}) in
    \texttt{\$IPOPTDIR/lib},
  \item and the necessary header files in
    \texttt{\$IPOPTDIR/include/ipopt}.
  \end{itemize}
  You can change the default installation directory (here
  \texttt{\$IPOPTDIR}) to something else (such as \texttt{/usr/local})
  by using the \verb|--prefix| switch for \texttt{configure}.
%\item Test the installation \\
%  {\tt \$ make test}\\
%  This should ?...?
\end{enumerate}

\subsection{Installation on Windows}\label{WindowsInstall}

There are two ways to install \Ipopt\ on Windows systems.  The first
option, described in Section~\ref{CygwinInstall}, is to use Cygwin (see
\texttt{www.cygwin.com}), which offers a UNIX-like environment
on Windows and in which the installation procedure described earlier
in this section can be used.  The \Ipopt\ distribution also includes
projects files for the Microsoft Visual Studio (see
Section~\ref{VisualStudioInstall}).

\subsubsection{Installation with Cygwin}\label{CygwinInstall}

Cygwin is a Linux-like environment for Windows; if you don't know what
it is you might want to have a look at the Cygwin homepage,
\texttt{www.cygwin.com}.

It is possible to build the \Ipopt\ AMPL solver executable in Cygwin
for general use in Windows.  You can also hook up \Ipopt\ to your own
program if you compile it in the Cygwin environment\footnote{It might
  also be possible to build an \Ipopt\ DLL that can be used from
  non-cygwin compilers, but this is not (yet?) supported.}.

If you want to compile \Ipopt\ under Cygwin, you first have to install
Cygwin in your Windows system.  This is pretty straight forward; you
simply download the ``setup'' program from
\texttt{www.cygwin.com} and start it.

Then you do the following steps (assuming here that you don't have any
complications with firewall settings etc - in that case you might have
to choose some connection settings differently):

\begin{enumerate}
\item Click next
\item Select ``install from the internet'' (default) and click next
\item Select a directory where Cygwin is to be installed (you can
  leave the default) and choose all other things to your liking, then
  click next
\item Select a temp dir for Cygwin setup to store some files (if you
  put it on your desktop you will later remember to delete it)
\item Select ``direct connection'' (default) and click next
\item Select some mirror site that seems close by to you and click next
\item OK, now comes the complicated part:\\
  You need to select the packages that you want to have installed.  By
  default, there are already selections, but the compilers are usually
  not pre-chosen.  You need to make sure that you select the GNU
  compilers (for Fortran, C, and C++ --- together with the MinGW
  options), the GNU Make, and Subversion.  For this, click on the "Devel"
  branch (which opens a subtree) and select:
  \begin{itemize}
  \item gcc
  \item gcc-core
  \item gcc-g77
  \item gcc-g++
  \item gcc-mingw
  \item gcc-mingw-core
  \item gcc-mingw-g77
  \item gcc-mingw-g++
  \item make
  \item subversion
  \end{itemize}

  Then, in the ``Web'' branch, please select ``wget'' (which will make
  the installation of third party dependencies for \Ipopt\ easier)

  This will automatically also select some other packages.
\item Then you click on next, and Cygwin will be installed (follow the
  rest of the instructions and choose everything else to your liking).
  At a later point you can easily add/remove packages with the setup
  program.

\item Now that you have Cygwin, you can open a Cygwin window, which is
  like a UNIX shell window.

\item Now you just follow the instructions in the beginning of
  Sections~\ref{Installing}:  You download the \Ipopt\ code into
  your Cygwin home directory (from the Windows explorer that is
  usually something like
  \texttt{C:$\backslash$Cygwin$\backslash$home$\backslash$your\_user\_name}).
  After that you obtain the third party code (like on Linux/UNIX),
  type

  \texttt{./configure}

  and

  \texttt{make install}

  in the correct directories, and hopefully that will work.  The
  \Ipopt\ AMPL solver executable will be in the subdirectory
  \texttt{bin} (called ``\texttt{ipopt.exe}'').
\end{enumerate}

\subsubsection{Using Visual Studio}\label{VisualStudioInstall}

The \Ipopt\ distribution includes project files that can be used to
compile the \Ipopt\ library and a Fortran and C++ example within the
Microsoft Visual Studio.  The project files have been created with
Microsoft Visual C++ .NET 2003 Standard, and the Intel Visual Fortran
Compiler 8.

In order to use those project files, download the \Ipopt\ source code,
as well as the required third party code (put it into the Extern/blas
and Extern/HSL directories---ASL is not required for the Fortran and C
examples). Then open the solution file\\

\texttt{\$IPOPTDIR$\backslash$Windows$\backslash$VisualStudio\_dotNET$\backslash$Ipopt$\backslash$Ipopt.sln}\\

Note: Since the project files were created only with the Standard
edition of the C++ compiler, code optimization might be disabled; for
fast performance make sure you enable code optimization.

\section{Interfacing your NLP to \Ipopt: A tutorial example.}
\label{sec:tutorial-example}

\Ipopt\ has been designed to be flexible for a wide variety of
applications, and there are a number of ways to interface with \Ipopt\
that allow specific data structures and linear solver
techniques. Nevertheless, the authors have included a standard
representation that should meet the needs of most users.

This tutorial will discuss four interfaces to \Ipopt, namely the AMPL
modeling language interface, and the C, C++, and Fortran code
interfaces.  AMPL is a 3rd party modeling language tool that allows
users to write their optimization problem in a syntax that resembles
the way the problem would be written mathematically. Once the problem
has been formulated in AMPL, the problem can be easily solved using
the (already compiled) executable. Interfacing your problem by
directly linking code requires more effort to write, but can be far
more efficient for large problems.

We will illustrate how to use each of the four interfaces using an
example problem, number 71 from the Hock-Schittkowsky test suite \cite{HS},
%\begin{subequations}\label{HS71}
  \begin{eqnarray}
    \min_{x \in \Re^4} &&x_1 x_4 (x_1 + x_2 + x_3)  +  x_3 \label{eq:ex_obj} \\
    \mbox{s.t.}  &&x_1 x_2 x_3 x_4 \ge 25 \label{eq:ex_ineq} \\
    &&x_1^2 + x_2^2 + x_3^2 + x_4^2  =  40 \label{eq:ex_equ} \\
    &&1 \leq x_1, x_2, x_3, x_4 \leq 5, \label{eq:ex_bounds}
  \end{eqnarray}
%\end{subequations}
with the starting point
\begin{equation}
x {=} (1, 5, 5, 1) \label{eq:ex_startpt}
\end{equation}
and the optimal solution
\[
x^\star {=} (1.00000000, 4.74299963, 3.82114998, 1.37940829). \nonumber
\]

\subsection{Using the AMPL interface}
Interfacing through the AMPL interface is by far the easiest way to
solve a problem with \Ipopt. The user must simply formulate the problem
in AMPL syntax, and solve the problem through the AMPL environment.
There are drawbacks, however. AMPL is a 3rd party package and, as
such, must be appropriately licensed (a free, student version for
limited problem size is available from the AMPL website,
\texttt{www.ampl.com}). Furthermore, the AMPL environment may be prohibitive
for very large problems. Nevertheless, formulating the problem in AMPL
is straightforward and even for large problems, it is often used as a
prototyping tool before using one of the code interfaces.

This tutorial is not intended as a guide to formulating models in
AMPL. If you are not already familiar with AMPL, please consult
\cite{FouGayKer:AMPLbook}.

The problem presented in equations
(\ref{eq:ex_obj})--(\ref{eq:ex_startpt}) can be solved with \Ipopt\ with
the AMPL model file given in Figure~\ref{fig:HS71}.

\begin{figure}
  \centering
\begin{footnotesize}
\begin{verbatim}
# tell ampl to use the ipopt executable as a solver
# make sure ipopt is in the path!
option solver ipopt;

# declare the variables and their bounds, 
# set notation could be used, but this is straightforward
var x1 >= 1, <= 5; 
var x2 >= 1, <= 5; 
var x3 >= 1, <= 5; 
var x4 >= 1, <= 5;

# specify the objective function
minimize obj:
                x1 * x4 * (x1 + x2 + x3) + x3;
        
# specify the constraints
s.t.
        inequality:
                x1 * x2 * x3 * x4 >= 25;
                
        equality:
                x1^2 + x2^2 + x3^2 +x4^2 = 40;

# specify the starting point            
let x1 := 1;
let x2 := 5;
let x3 := 5;
let x4 := 1;

# solve the problem
solve;

# print the solution
display x1;
display x2;
display x3;
display x4;
\end{verbatim}
\end{footnotesize}
  
  \caption{AMPL model file hs071\_ampl.mod}
  \label{fig:HS71}
\end{figure}

The line, ``{\tt option solver ipopt;}'' tells AMPL to use \Ipopt\ as
the solver. The \Ipopt\ executable (installed in
Section~\ref{sec.comp_and_inst}) must be in the path for AMPL to find
it. The remaining lines specify the problem in AMPL format. The
problem can now be solved by starting AMPL and loading the mod file:
\begin{verbatim}
$ ampl
> model hs071_ampl.mod;
.
.
.
\end{verbatim}
%$
The problem will be solved using \Ipopt\ and the solution will be
displayed.

At this point, AMPL users may wish to skip the sections about
interfacing with code, but should read Section \ref{sec.options}
concerning \Ipopt\ options, and Section \ref{sec.output} which
explains the output displayed by \Ipopt.

\subsection{Interfacing with \Ipopt\ through code}
In order to solve a problem, \Ipopt\ needs more information than just
the problem definition (for example, the derivative information). If
you are using a modeling language like AMPL, the extra information is
provided by the modeling tool and the \Ipopt\ interface. When
interfacing with \Ipopt\ through your own code, however, you must
provide this additional information.

\begin{figure}
\begin{enumerate}
\item Problem dimensions \label{it.prob_dim}
  \begin{itemize}
  \item number of variables
  \item number of constraints
  \end{itemize}
\item Problem bounds
  \begin{itemize}
  \item variable bounds
  \item constraint bounds
  \end{itemize}
\item Initial starting point
  \begin{itemize}
  \item Initial values for the primal $x$ variables
  \item Initial values for the multipliers (only
    required for a warm start option)
  \end{itemize}
\item Problem Structure \label{it.prob_struct}
  \begin{itemize}
  \item number of nonzeros in the Jacobian of the constraints
  \item number of nonzeros in the Hessian of the Lagrangian
  \item Structure of the Jacobian of the constraints
  \item Structure of the Hessian of the Lagrangian
  \end{itemize}
\item Evaluation of Problem Functions \label{it.prob_eval} \\
  Information evaluated using a given point ($x_k,
  \lambda_k, \sigma_f$ coming from \Ipopt)
  \begin{itemize}
  \item Objective function, $f(x_k)$
  \item Gradient of the objective $\nabla f(x_k)$
  \item Constraint residuals, $g(x_k)$
  \item Jacobian of the constraints, $\nabla g(x_k)$
  \item Hessian of the Lagrangian, 
    $\sigma_f \nabla^2 f(x_k) + \sum_{i=1}^m\lambda_i\nabla^2 g_i(x_k)$ 
  \end{itemize}
\end{enumerate}
\caption{Information Required By \Ipopt}
\label{fig.required_info}
\end{figure}
%\vspace{0.1in}
The information required by \Ipopt\ is shown in Figure
\ref{fig.required_info}. The problem dimensions and bounds are
straightforward and come solely from the problem definition. The
initial starting point is used by the algorithm when it begins
iterating to solve the problem. If \Ipopt\ has difficulty converging, or
if it converges to a locally infeasible point, adjusting the starting
point may help.

Providing the problem structure is a bit more involved. \Ipopt\ is a
nonlinear programming solver that is designed for solving large scale,
sparse problems. While \Ipopt\ can be customized for a variety of matrix
formats, the triplet format is used for the standard interfaces in this
tutorial. For an overview of the triplet format for sparse matrices,
see Appendix~\ref{app.triplet}. Before solving the problem, \Ipopt\
needs to know the number of nonzeros and the structure (row and column
indices of each of the nonzeros) of the Jacobian and the Hessian. Once
defined, this nonzero structure MUST remain constant for the entire
problem. This means that the structure needs to include entries for
any element that could ever be nonzero, not only those that are
nonzero at the starting point.

As \Ipopt\ iterates, it will need the values for the items in
(\ref{it.prob_eval}) evaluated at particular points. Before we can
begin coding the interface, however, we need to work out the details
of these equations symbolically for example problem
(\ref{eq:ex_obj}-\ref{eq:ex_bounds}).

The gradient of the objective $f(x)$ is given by
\begin{equation}
\left[
\begin{array}{c}
x_1 x_4 + x_4 (x_1 + x_2 + x_3) \\
x_1 x_4 \\
x_1 x_4 + 1 \\
x_1 (x_1 + x_2 + x_3)
\end{array}
\right],
\end{equation}
the Jacobian of 
the constraints $g(x)$ is,
\begin{equation}
\left[
\begin{array}{cccc}
x_2 x_3 x_4     & x_1 x_3 x_4   & x_1 x_2 x_4   & x_1 x_2 x_3   \\
2 x_1           & 2 x_2         & 2 x_3         & 2 x_4
\end{array}
\right].
\end{equation}

We need to determine the Hessian of the Lagrangian.  The Lagrangian is
given by $f(x) + g(x)^T \lambda$ and the Hessian of the Lagrangian is
technically, $ \nabla^2 f(x_k) + \sum_{i=1}^m\lambda_i\nabla^2 g_i(x_k)$.
However, so that \Ipopt\ can ask for the Hessian of the objective or the
constraints independently if required, we introduce a factor
($\sigma_f$) in front of the objective term. The value for $\sigma_f$
is generally $1$, although it may include scaling factors or even be
set to zero to retrieve the Hessians of the constraints alone.

For our implementation then, the symbolic form of the Hessian of the
Lagrangian
\[
\sigma_f \nabla^2 f(x_k) + \sum_{i=1}^m\lambda_i\nabla^2 g_i(x_k)
\]
(with the $\sigma_f$ parameter) is,
%\begin{eqnarray}
%{\cal L}(x,\lambda) &{=}& f(x) + c(x)^T \lambda \nonumber \\
%&{=}& \left(x_1 x_4 (x_1 + x_2 + x_3)  +  x_3\right) 
%+ \left(x_1 x_2 x_3 x_4\right) \lambda_1 \nonumber \\
%&& \;\;\;\;\;+ \left(x_1^2 + x_2^2 + x_3^2 + x_4^2\right) \lambda_2 
%- \displaystyle \sum_{i \in 1..4} z^L_i + \sum_{i \in 1..4} z^U_i
%\end{eqnarray}
\begin{equation}
\sigma_f \left[
\begin{array}{cccc}
2 x_4           & x_4           & x_4           & 2 x_1 + x_2 + x_3     \\
x_4             & 0             & 0             & x_1                   \\
x_4             & 0             & 0             & x_1                   \\
2 x_1+x_2+x_3   & x_1           & x_1           & 0
\end{array}
\right]
+
\lambda_1
\left[
\begin{array}{cccc}
0               & x_3 x_4       & x_2 x_4       & x_2 x_3       \\
x_3 x_4         & 0             & x_1 x_4       & x_1 x_3       \\
x_2 x_4         & x_1 x_4       & 0             & x_1 x_2       \\
x_2 x_3         & x_1 x_3       & x_1 x_2       & 0 
\end{array}
\right]
+
\lambda_2
\left[
\begin{array}{cccc}
2       & 0     & 0     & 0     \\
0       & 2     & 0     & 0     \\
0       & 0     & 2     & 0     \\
0       & 0     & 0     & 2
\end{array}
\right]
\end{equation}
where the first term comes from the Hessian of the objective function,
and the second and third term from the Hessian of (\ref{eq:ex_ineq})
and (\ref{eq:ex_equ}) respectively. Therefore, the dual variables
$\lambda_1$ and $\lambda_2$ are then the multipliers for constraints
(\ref{eq:ex_ineq}) and (\ref{eq:ex_equ}) respectively.

%C =============================================================================
%C
%C     This is an example for the usage of IPOPT.
%C     It implements problem 71 from the Hock-Schittkowsky test suite:
%C
%C     min   x1*x4*(x1 + x2 + x3)  +  x3
%C     s.t.  x1*x2*x3*x4                   >=  25
%C           x1**2 + x2**2 + x3**2 + x4**2  =  40
%C           1 <=  x1,x2,x3,x4  <= 5
%C
%C     Starting point:
%C        x = (1, 5, 5, 1)
%C
%C     Optimal solution:
%C        x = (1.00000000, 4.74299963, 3.82114998, 1.37940829)
%C
%C =============================================================================
\vspace{\baselineskip}

The remaining sections of the tutorial will lead you through
the coding required to solve example problem
(\ref{eq:ex_obj})--(\ref{eq:ex_bounds}) using, first C++, then C, and finally
Fortran. Completed versions of these examples can be found in {\tt
\$IPOPTDIR/Examples} under {\tt hs071\_cpp}, {\tt hs071\_c}, {\tt
hs071\_f}.

As a user, you are responsible for coding two sections of the program
that solves a problem using \Ipopt: the main executable (e.g., {\tt
  main}) and the problem representation.  Typically, you will write an
executable that prepares the problem, and then passes control over to
\Ipopt\ through an {\tt Optimize} or {\tt Solve} call. In this call,
you will give \Ipopt\ everything that it requires to call back to your
code whenever it needs functions evaluated (like the objective, the
Jacobian, etc.).  In each of the three sections that follow (C++, C,
and Fortran), we will first discuss how to code the problem
representation, and then how to code the executable.

\subsection{The C++ Interface}
This tutorial assumes that you are familiar with the C++ programming
language, however, we will lead you through each step of the
implementation. For the problem representation, we will create a class
that inherits off of the pure virtual base class, {\tt TNLP} ({\tt
  IpTNLP.hpp}). For the executable (the {\tt main} function) we will
make the call to \Ipopt\ through the {\tt IpoptApplication} class
({\tt IpIpoptApplication.hpp}). In addition, we will also be using the
SmartPtr class ({\tt IpSmartPtr.hpp}) which implements a reference
counting pointer that takes care of memory management (object
deletion) for you.

After ``\texttt{make install}'' (see Section~\ref{sec.comp_and_inst}),
the header files are installed in \texttt{\$IPOPTDIR/include/ipopt}
(or in \texttt{\$PREFIX/include/ipopt} if the switch
\verb|--prefix=$PREFIX| was used for {\tt configure}).

\subsubsection{Coding the Problem Representation}\label{sec.cpp_problem}
We provide the information required in Figure \ref{fig.required_info}
by coding the {\tt HS071\_NLP} class, a specific implementation of the
{\tt TNLP} base class. In the executable, we will create an instance
of the {\tt HS071\_NLP} class and give this class to \Ipopt\ so it can
evaluate the problem functions through the {\tt TNLP} interface. If
you have any difficulty as the implementation proceeds, have a look at
the completed example in the {\tt Example/hs071\_cpp} directory.

Start by creating a new directory under Examples, called {\tt MyExample} and
create the files {\tt hs071\_nlp.hpp} and {\tt hs071\_nlp.cpp}. In
{\tt hs071\_nlp.hpp}, include {\tt IpTNLP.hpp} (the base class), tell
the compiler that we are using the \Ipopt\ namespace, and create the
declaration of the {\tt HS071\_NLP} class, inheriting off of {\tt
  TNLP}. Have a look at the {\tt TNLP} class in {\tt IpTNLP.hpp}; you
will see eight pure virtual methods that we must implement. Declare
these methods in the header file.  Implement each of the methods in
{\tt HS071\_NLP.cpp} using the descriptions given below. In {\tt
  hs071\_nlp.cpp}, first include the header file for your class and
tell the compiler that you are using the \Ipopt\ namespace. A full
version of these files can be found in the {\tt Examples/hs071\_cpp}
directory.

\paragraph{Method {\texttt{get\_nlp\_info}}} with Prototype
\begin{verbatim}
virtual bool get_nlp_info(Index& n, Index& m, Index& nnz_jac_g,
                          Index& nnz_h_lag, IndexStyleEnum& index_style)
\end{verbatim}
Give \Ipopt\ the information about the size of the problem (and hence,
the size of the arrays that it needs to allocate). 
\begin{itemize}
\item {\tt n}: (out), the number of variables in the problem (dimension of {\tt x}).
\item {\tt m}: (out), the number of constraints in the problem (dimension of {\tt g}).
\item {\tt nnz\_jac\_g}: (out), the number of nonzero entries in the Jacobian.
\item {\tt nnz\_h\_lag}: (out), the number of nonzero entries in the Hessian.
\item {\tt index\_style}: (out), the style used for row/col entries in the sparse matrix
format ({\tt C\_STYLE}: 0-based, {\tt FORTRAN\_STYLE}: 1-based).
\end{itemize}
\Ipopt\ uses this information when allocating the arrays that
it will later ask you to fill with values. Be careful in this method
since incorrect values will cause memory bugs which may be very
difficult to find.

Our example problem has 4 variables (n), and two constraints (m). The
Jacobian for this small problem is actually dense and has 8 nonzeros
(we will still represent this Jacobian using the sparse matrix triplet
format). The Hessian of the Lagrangian has 10 ``symmetric'' nonzeros.
Keep in mind that the number of nonzeros is the total number of
elements that may \emph{ever} be nonzero, not just those that are
nonzero at the starting point. This information is set once for the
entire problem.

\begin{footnotesize}
\begin{verbatim}
bool HS071_NLP::get_nlp_info(Index& n, Index& m, Index& nnz_jac_g, 
                             Index& nnz_h_lag, IndexStyleEnum& index_style)
{
  // The problem described in HS071_NLP.hpp has 4 variables, x[0] through x[3]
  n = 4;

  // one equality constraint and one inequality constraint
  m = 2;

  // in this example the Jacobian is dense and contains 8 nonzeros
  nnz_jac_g = 8;

  // the Hessian is also dense and has 16 total nonzeros, but we
  // only need the lower left corner (since it is symmetric)
  nnz_h_lag = 10;

  // use the C style indexing (0-based)
  index_style = TNLP::C_STYLE;

  return true;
}
\end{verbatim}
\end{footnotesize}

\paragraph{Method {\texttt{get\_bounds\_info}}} with Prototype
\begin{verbatim}
virtual bool get_bounds_info(Index n, Number* x_l, Number* x_u,
                             Index m, Number* g_l, Number* g_u)
\end{verbatim}
Give \Ipopt\ the value of the bounds on the variables and constraints.
\begin{itemize}
\item {\tt n}: (in), the number of variables in the problem (dimension of {\tt x}). 
\item {\tt x\_l}: (out) the lower bounds for {\tt x}. 
\item {\tt x\_u}: (out) the upper bounds for {\tt x}.
\item {\tt m}: (in), the number of constraints in the problem (dimension of {\tt g}).
\item {\tt g\_l}: (out) the lower bounds for {\tt g}. 
\item {\tt g\_u}: (out) the upper bounds for {\tt g}.
\end{itemize}
The values of {\tt n} and {\tt m} that you specified in {\tt
  get\_nlp\_info} are passed to you for debug checking.  Setting a
lower bound to a value less than or equal to the value of the option
{\tt nlp\_lower\_bound\_inf} (data member of {\tt TNLP}) will cause
\Ipopt\ to assume no lower bound. Likewise, specifying the upper bound
above or equal to the value of the option {\tt nlp\_upper\_bound\_inf}
will cause \Ipopt\ to assume no upper bound.  These options, {\tt
  nlp\_lower\_bound\_inf} and {\tt nlp\_upper\_bound\_inf}, are set to
$-10^{19}$ and $10^{19}$ respectively, by default, but may be modified
by changing the options (see Section \ref{sec.options}).

In our example, the first constraint has a lower bound of $25$ and no upper
bound, so we set the lower bound of constraint {\tt [0]} to $25$ and
the upper bound to some number greater than $10^{19}$. The second
constraint is an equality constraint and we set both bounds to
$40$. \Ipopt\ recognizes this as an equality constraint and does not
treat it as two inequalities.

\begin{footnotesize}
\begin{verbatim}
bool HS071_NLP::get_bounds_info(Index n, Number* x_l, Number* x_u,
                                Index m, Number* g_l, Number* g_u)
{
  // here, the n and m we gave IPOPT in get_nlp_info are passed back to us.
  // If desired, we could assert to make sure they are what we think they are.
  assert(n == 4);
  assert(m == 2);

  // the variables have lower bounds of 1
  for (Index i=0; i<4; i++) {
    x_l[i] = 1.0;
  }

  // the variables have upper bounds of 5
  for (Index i=0; i<4; i++) {
    x_u[i] = 5.0;
  }

  // the first constraint g1 has a lower bound of 25
  g_l[0] = 25;
  // the first constraint g1 has NO upper bound, here we set it to 2e19.
  // Ipopt interprets any number greater than nlp_upper_bound_inf as 
  // infinity. The default value of nlp_upper_bound_inf and nlp_lower_bound_inf
  // is 1e19 and can be changed through ipopt options.
  g_u[0] = 2e19;

  // the second constraint g2 is an equality constraint, so we set the 
  // upper and lower bound to the same value
  g_l[1] = g_u[1] = 40.0;

  return true;
}
\end{verbatim}
\end{footnotesize}

\paragraph{Method {\texttt{get\_starting\_point}}} with Prototype
\begin{verbatim}
virtual bool get_starting_point(Index n, bool init_x, Number* x,
                                bool init_z, Number* z_L, Number* z_U,
                                Index m,  bool init_lambda, Number* lambda)
\end{verbatim}
Give \Ipopt\ the starting point before it begins iterating.
\begin{itemize}
\item {\tt n}: (in), the number of variables in the problem (dimension of {\tt x}). 
\item {\tt init\_x}: (in), if true, this method must provide an initial value for {\tt x}.
\item {\tt x}: (out), the initial values for the primal variables, {\tt x}.
\item {\tt init\_z}: (in), if true, this method must provide an initial value 
        for the bound multipliers {\tt z\_L}, and {\tt z\_U}.
\item {\tt z\_L}: (out), the initial values for the bound multipliers, {\tt z\_L}.
\item {\tt z\_U}: (out), the initial values for the bound multipliers, {\tt z\_U}.
\item {\tt m}: (in), the number of constraints in the problem (dimension of {\tt g}).
\item {\tt init\_lambda}: (in), if true, this method must provide an initial value 
        for the constraint multipliers, {\tt lambda}.
\item {\tt lambda}: (out), the initial values for the constraint multipliers, {\tt lambda}.
\end{itemize}

The index variables $n$, and $m$ are passed in only to help your
debugging. These variables will have the same values you specified in
{\tt get\_nlp\_info}.

Depending on the options that have been set,
\Ipopt\ may or may not require bounds for the primal variables $x$, the
bound multipliers $z$, and the equality multipliers $\lambda$. The
boolean flags {\tt init\_x},{\tt init\_z}, and {\tt init\_lambda} tell
you whether or not you should provide initial values for $x$, $z$, or
$\lambda$ respectively. The default options only require an
initial value for the primal variables {\tt x}.

In our example, we provide initial values for {\tt x} as specified in the example
problem. We do not provide any initial values for the dual variables,
but use an assert to immediately let us know if we are ever asked for
them.

\begin{footnotesize}
\begin{verbatim}
bool HS071_NLP::get_starting_point(Index n, bool init_x, Number* x,
                                   bool init_z, Number* z_L, Number* z_U,
                                   Index m, bool init_lambda,
                                   Number* lambda)
{
  // Here, we assume we only have starting values for x, if you code
  // your own NLP, you can provide starting values for the dual variables
  // if you wish to use a warmstart option
  assert(init_x == true);
  assert(init_z == false);
  assert(init_lambda == false);

  // initialize to the given starting point
  x[0] = 1.0;
  x[1] = 5.0;
  x[2] = 5.0;
  x[3] = 1.0;

  return true;
}
\end{verbatim}
\end{footnotesize}

\paragraph{Method {\texttt{eval\_f}}} with Prototype
\begin{verbatim}
virtual bool eval_f(Index n, const Number* x, 
                    bool new_x, Number& obj_value)
\end{verbatim}
Return the value of the objective function as calculated using {\tt x}.
\begin{itemize}
\item {\tt n}: (in), the number of variables in the problem (dimension
  of {\tt x}).
\item {\tt x}: (in), the current values for the primal variables, {\tt
    x}.
\item {\tt new\_x}: (in), false if any evaluation method was
  previously called with the same values in {\tt x}, true otherwise.
\item {\tt obj\_value}: (out) the value of the objective function
  ($f(x)$).
\end{itemize}

The boolean variable {\tt new\_x} will be false if the last call to
any of the evaluation methods used the same $x$ values. This can be
helpful when users have efficient implementations that calculate
multiple outputs at once. \Ipopt\ internally caches results from the
{\tt TNLP} and generally, this flag can be ignored.

The index variable $n$ is passed in only to help your debugging. This
variable will have the same value you specified in {\tt
get\_nlp\_info}.

For our example, we ignore the {\tt new\_x} flag and calculate the objective.

\begin{footnotesize}
\begin{verbatim}
bool HS071_NLP::eval_f(Index n, const Number* x, bool new_x, Number& obj_value)
{
  assert(n == 4);

  obj_value = x[0] * x[3] * (x[0] + x[1] + x[2]) + x[2];

  return true;
}
\end{verbatim}
\end{footnotesize}

\paragraph{Method {\texttt{eval\_grad\_f}}} with Prototype
\begin{verbatim}
virtual bool eval_grad_f(Index n, const Number* x, bool new_x, 
                         Number* grad_f)
\end{verbatim}
Return the gradient of the objective to \Ipopt, as calculated by the values in {\tt x}.
\begin{itemize}
\item {\tt n}: (in), the number of variables in the problem (dimension of {\tt x}). 
\item {\tt x}: (in), the current values for the primal variables, {\tt x}.
\item {\tt new\_x}: (in), false if any evaluation method was previously called 
        with the same values in {\tt x}, true otherwise.
\item {\tt grad\_f}: (out) the array of values for the gradient of the 
        objective function ($\nabla f(x)$).
\end{itemize}

The gradient array is in the same order as the $x$ variables (i.e.\ the
gradient of the objective with respect to {\tt x[2]} should be put in
{\tt grad\_f[2]}).

The boolean variable {\tt new\_x} will be false if the last call to
any of the evaluation methods used the same $x$ values. This can be
helpful when users have efficient implementations that calculate
multiple outputs at once. \Ipopt\ internally caches results from the
{\tt TNLP} and generally, this flag can be ignored.

The index variable $n$ is passed in only to help your debugging. This
variable will have the same value you specified in {\tt
get\_nlp\_info}.

In our example, we ignore the {\tt new\_x} flag and calculate the
values for the gradient of the objective.
\begin{footnotesize}
\begin{verbatim}
bool HS071_NLP::eval_grad_f(Index n, const Number* x, bool new_x, Number* grad_f)
{
  assert(n == 4);

  grad_f[0] = x[0] * x[3] + x[3] * (x[0] + x[1] + x[2]);
  grad_f[1] = x[0] * x[3];
  grad_f[2] = x[0] * x[3] + 1;
  grad_f[3] = x[0] * (x[0] + x[1] + x[2]);

  return true;
}
\end{verbatim}
\end{footnotesize}

\paragraph{Method {\texttt{eval\_g}}} with Prototype
\begin{verbatim}
virtual bool eval_g(Index n, const Number* x, 
                    bool new_x, Index m, Number* g)}
\end{verbatim}
Give \Ipopt\ the value of the constraints as calculated by the values in {\tt x}.
\begin{itemize}
\item {\tt n}: (in), the number of variables in the problem (dimension of {\tt x}). 
\item {\tt x}: (in), the current values for the primal variables, {\tt x}.
\item {\tt new\_x}: (in), false if any evaluation method was previously called 
        with the same values in {\tt x}, true otherwise.
\item {\tt m}: (in), the number of constraints in the problem (dimension of {\tt g}).
\item {\tt g}: (out) the array of constraint residuals.
\end{itemize}

The values returned in {\tt g} should be only the $g(x)$ values, 
do not add or subtract the bound values $g_l$ or $g_u$.

The boolean variable {\tt new\_x} will be false if the last call to
any of the evaluation methods used the same $x$ values. This can be
helpful when users have efficient implementations that calculate
multiple outputs at once. \Ipopt\ internally caches results from the
{\tt TNLP} and generally, this flag can be ignored.

The index variables $n$, and $m$ are passed in only to help your
debugging. These variables will have the same values you specified in
{\tt get\_nlp\_info}.

In our example, we ignore the {\tt new\_x} flag and calculate the
values for the gradient of the objective.
\begin{footnotesize}
\begin{verbatim}
bool HS071_NLP::eval_g(Index n, const Number* x, bool new_x, Index m, Number* g)
{
  assert(n == 4);
  assert(m == 2);

  g[0] = x[0] * x[1] * x[2] * x[3];
  g[1] = x[0]*x[0] + x[1]*x[1] + x[2]*x[2] + x[3]*x[3];

  return true;
} 
\end{verbatim}
\end{footnotesize}

\paragraph{Method {\texttt{eval\_jac\_g}}} with Prototype
\begin{verbatim}
virtual bool eval_jac_g(Index n, const Number* x, bool new_x,
                        Index m, Index nele_jac, Index* iRow, 
                        Index *jCol, Number* values)
\end{verbatim}
Return either the structure of the Jacobian of the constraints, or the values for the 
Jacobian of the constraints as calculated by the values in {\tt x}.
\begin{itemize}
\item {\tt n}: (in), the number of variables in the problem (dimension of {\tt x}). 
\item {\tt x}: (in), the current values for the primal variables, {\tt x}.
\item {\tt new\_x}: (in), false if any evaluation method was previously called 
        with the same values in {\tt x}, true otherwise.
\item {\tt m}: (in), the number of constraints in the problem (dimension of {\tt g}).
\item {\tt n\_elel\_jac}: (in), the number of nonzero elements in the 
        Jacobian (dimension of {\tt iRow}, {\tt jCol}, and {\tt values}).
\item {\tt iRow}: (out), the row indices of entries in the Jacobian of the constraints.
\item {\tt jCol}: (out), the column indices of entries in the Jacobian of the constraints.
\item {\tt values}: (out), the values of the entries in the Jacobian of the constraints.
\end{itemize}

The Jacobian is the matrix of derivatives where
the derivative of constraint $i$ with respect to variable $j$ is
placed in row $i$ and column $j$. See Appendix \ref{app.triplet} for a discussion of 
the sparse matrix format used in this method.

If the {\tt iRow} and {\tt jCol} arguments are not NULL, then \Ipopt
wants you to fill in the structure of the Jacobian (the row and column
indices only). At this time, the {\tt x} argument and the {\tt values}
argument will be NULL.

If the {\tt x} argument and the {\tt values} argument are not NULL,
then \Ipopt\ wants you to fill in the values of the Jacobian as
calculated from the array {\tt x} (using the same order as you used
when specifying the structure). At this time, the {\tt iRow} and {\tt
jCol} arguments will be NULL;

The boolean variable {\tt new\_x} will be false if the last call to
any of the evaluation methods used the same $x$ values. This can be
helpful when users have efficient implementations that calculate
multiple outputs at once. \Ipopt\ internally caches results from the
{\tt TNLP} and generally, this flag can be ignored.

The index variables {\tt n}, {\tt m}, and {\tt nele\_jac} are passed
in only to help your debugging. These arguments will have the same
values you specified in {\tt get\_nlp\_info}.

In our example, the Jacobian is actually dense, but we still
specify it using the sparse format.

\begin{footnotesize}
\begin{verbatim}
bool HS071_NLP::eval_jac_g(Index n, const Number* x, bool new_x,
                           Index m, Index nele_jac, Index* iRow, Index *jCol,
                           Number* values)
{
  if (values == NULL) {
    // return the structure of the Jacobian

    // this particular Jacobian is dense
    iRow[0] = 0; jCol[0] = 0;
    iRow[1] = 0; jCol[1] = 1;
    iRow[2] = 0; jCol[2] = 2;
    iRow[3] = 0; jCol[3] = 3;
    iRow[4] = 1; jCol[4] = 0;
    iRow[5] = 1; jCol[5] = 1;
    iRow[6] = 1; jCol[6] = 2;
    iRow[7] = 1; jCol[7] = 3;
  }
  else {
    // return the values of the Jacobian of the constraints
    
    values[0] = x[1]*x[2]*x[3]; // 0,0
    values[1] = x[0]*x[2]*x[3]; // 0,1
    values[2] = x[0]*x[1]*x[3]; // 0,2
    values[3] = x[0]*x[1]*x[2]; // 0,3

    values[4] = 2*x[0]; // 1,0
    values[5] = 2*x[1]; // 1,1
    values[6] = 2*x[2]; // 1,2
    values[7] = 2*x[3]; // 1,3
  }

  return true;
}
\end{verbatim}
\end{footnotesize}

\paragraph{Method {\texttt{eval\_h}}} with Prototype
\begin{verbatim}
virtual bool eval_h(Index n, const Number* x, bool new_x,
                    Number obj_factor, Index m, const Number* lambda,
                    bool new_lambda, Index nele_hess, Index* iRow,
                    Index* jCol, Number* values)
\end{verbatim}
Return the structure of the Hessian of the Lagrangian or the values of the 
Hessian of the Lagrangian as calculated by the values in {\tt obj\_factor},
{\tt x}, and {\tt lambda}.
\begin{itemize}
\item {\tt n}: (in), the number of variables in the problem (dimension of {\tt x}). 
\item {\tt x}: (in), the current values for the primal variables, {\tt x}.
\item {\tt new\_x}: (in), false if any evaluation method was previously called 
        with the same values in {\tt x}, true otherwise.
\item {\tt obj\_factor}: (in), factor in front of the objective term in the Hessian.
\item {\tt m}: (in), the number of constraints in the problem (dimension of {\tt g}).
\item {\tt lambda}: (in), the current values of the equality multipliers to use
        for each constraint in the evaluation of the Hessian.
\item {\tt n\_elel\_jac}: (in), the number of nonzero elements in the 
        Jacobian (dimension of {\tt iRow}, {\tt jCol}, and {\tt values}).
\item {\tt new\_lambda}: (in), false if any evaluation method was previously called 
        with the same values in {\tt lambda}, true otherwise.
\item {\tt nele\_hess}: (in), the number of nonzero elements in the Hessian 
        (dimension of {\tt iRow}, {\tt jCol}, and {\tt values}.
\item {\tt iRow}: (out), the row indices of entries in the Hessian.
\item {\tt jCol}: (out), the column indices of entries in the Hessian.
\item {\tt values}: (out), the values of the entries in the Hessian.
\end{itemize}

If the {\tt iRow} and {\tt jCol} arguments are not NULL, then \Ipopt
wants you to fill in the structure of the Hessian (the row and column
indices only). In this case, the {\tt x}, {\tt lambda}, and {\tt
values} arrays will be NULL.

If the {\tt x}, {\tt lambda}, and {\tt values} arrays are not NULL,
then \Ipopt\ wants you to fill in the values of the Hessian as
calculated using {\tt x} and {\tt lambda} (using the same order as you
used when specifying the structure). In this case, the {\tt iRow} and
{\tt jCol} arguments will be NULL.

The boolean variables {\tt new\_x} and {\tt new\_lambda} will both be
false if the last call to any of the evaluation methods used the same
values. This can be helpful when users have efficient implementations
that calculate multiple outputs at once. \Ipopt\ internally caches
results from the {\tt TNLP} and generally, this flag can be ignored.

The index variables {\tt n}, {\tt m}, and {\tt nele\_hess} are passed
in only to help your debugging. These arguments will have the same
values you specified in {\tt get\_nlp\_info}.

In our example, the Hessian is dense, but we still specify it using the
sparse matrix format. Because the Hessian is symmetric, we only need to 
specify the lower left corner.
\begin{footnotesize}
\begin{verbatim}
bool HS071_NLP::eval_h(Index n, const Number* x, bool new_x,
                       Number obj_factor, Index m, const Number* lambda,
                       bool new_lambda, Index nele_hess, Index* iRow,
                       Index* jCol, Number* values)
{
  if (values == NULL) {
    // return the structure. This is a symmetric matrix, fill the lower left
    // triangle only.

    // the Hessian for this problem is actually dense
    Index idx=0;
    for (Index row = 0; row < 4; row++) {
      for (Index col = 0; col <= row; col++) {
        iRow[idx] = row; 
        jCol[idx] = col;
        idx++;
      }
    }
    
    assert(idx == nele_hess);
  }
  else {
    // return the values. This is a symmetric matrix, fill the lower left
    // triangle only

    // fill the objective portion
    values[0] = obj_factor * (2*x[3]); // 0,0

    values[1] = obj_factor * (x[3]);   // 1,0
    values[2] = 0;                     // 1,1

    values[3] = obj_factor * (x[3]);   // 2,0
    values[4] = 0;                     // 2,1
    values[5] = 0;                     // 2,2

    values[6] = obj_factor * (2*x[0] + x[1] + x[2]); // 3,0
    values[7] = obj_factor * (x[0]);                 // 3,1
    values[8] = obj_factor * (x[0]);                 // 3,2
    values[9] = 0;                                   // 3,3


    // add the portion for the first constraint
    values[1] += lambda[0] * (x[2] * x[3]); // 1,0
    
    values[3] += lambda[0] * (x[1] * x[3]); // 2,0
    values[4] += lambda[0] * (x[0] * x[3]); // 2,1

    values[6] += lambda[0] * (x[1] * x[2]); // 3,0
    values[7] += lambda[0] * (x[0] * x[2]); // 3,1
    values[8] += lambda[0] * (x[0] * x[1]); // 3,2

    // add the portion for the second constraint
    values[0] += lambda[1] * 2; // 0,0

    values[2] += lambda[1] * 2; // 1,1

    values[5] += lambda[1] * 2; // 2,2

    values[9] += lambda[1] * 2; // 3,3
  }

  return true;
}
\end{verbatim}
\end{footnotesize}

\paragraph{Method \texttt{finalize\_solution}} with Prototype
\begin{verbatim}
virtual void finalize_solution(SolverReturn status, Index n,
                               const Number* x, const Number* z_L,
                               const Number* z_U, Index m, const Number* g,
                               const Number* lambda, Number obj_value)
\end{verbatim}
This is the only method that is not mentioned in Figure
\ref{fig.required_info}. This method is called by \Ipopt\ after the
algorithm has finished (successfully or even with most errors).
\begin{itemize}
\item {\tt status}: (in), gives the status of the algorithm 
        as specified in {\tt IpAlgTypes.hpp},
        \begin{itemize}
        \item {\tt SUCCESS}: Algorithm terminated successfully 
        at a locally optimal point.
        \item {\tt MAXITER\_EXCEEDED}: Maximum number of iterations 
        exceeded (can be specified by an option).
        \item {\tt STOP\_AT\_TINY\_STEP}: Algorithm proceeds with very little
        progress. 
        \item {\tt STOP\_AT\_ACCEPTABLE\_POINT}: Algorithm stopped at a point
        that was converged, not to ``desired'' tolerances, 
        but to ``acceptable'' tolerances (see the ??? options).
        \item {\tt LOCAL\_INFEASIBILITY}: Algorithm converged to a point 
        of local infeasibility. Problem may be infeasible.
        \item {\tt RESTORATION\_FAILURE}: Restoration phase was called, but 
        failed to find a more feasible point.
        \item {\tt INTERNAL\_ERROR}: An unknown internal error occurred. Please
        contact the \Ipopt\ Authors through the mailing list.
        \end{itemize}
\item {\tt n}: (in), the number of variables in the problem (dimension of {\tt x}). 
\item {\tt x}: (in), the current values for the primal variables, {\tt x}.
\item {\tt z\_L}: (in), the current values for the lower bound multipliers.
\item {\tt z\_U}: (in), the current values for the upper bound multipliers.
\item {\tt m}: (in), the number of constraints in the problem (dimension of {\tt g}).
\item {\tt g}: (in), the current value of the constraint residuals.
\item {\tt lambda}: (in), the current values of the equality multipliers.
\item {\tt obj\_value}: (in), the current value of the objective.
\end{itemize}

This method gives you the return status of the algorithm
(SolverReturn), and the values of the variables, 
the objective and constraint residuals when the algorithm exited.

In our example, we will print the values of some of the variables to 
the screen.

\begin{footnotesize}
\begin{verbatim}
void HS071_NLP::finalize_solution(SolverReturn status,
                                  Index n, const Number* x, const Number* z_L,
                                  const Number* z_U, Index m, const Number* g,
                                  const Number* lambda, Number obj_value)
{
  // here is where we would store the solution to variables, or write to a file, etc
  // so we could use the solution. 

  // For this example, we write the solution to the console
  printf("\n\nSolution of the primal variables, x\n");
  for (Index i=0; i<n; i++) {
    printf("x[%d] = %e\n", i, x[i]); 
  }

  printf("\n\nSolution of the bound multipliers, z_L and z_U\n");
  for (Index i=0; i<n; i++) {
    printf("z_L[%d] = %e\n", i, z_L[i]); 
  }
  for (Index i=0; i<n; i++) {
    printf("z_U[%d] = %e\n", i, z_U[i]); 
  }

  printf("\n\nObjective value\n");
  printf("f(x*) = %e\n", obj_value); 
}
\end{verbatim}
\end{footnotesize}

This is all that is required for our {\tt HS071\_NLP} class and 
the coding of the problem representation.
 
\subsubsection{Coding the Executable (\texttt{main})}
Now that we have a problem representation, the {\tt HS071\_NLP} class,
we need to code the main function that will call \Ipopt\ and ask \Ipopt\
to find a solution.

Here, we must create an instance of our problem ({\tt HS071\_NLP}),
create an instance of the \Ipopt\ solver (\texttt{IpoptApplication}),
and ask the solver to find a solution. We always use the
\texttt{SmartPtr} template class instead of raw C++ pointers when
creating and passing \Ipopt\ objects. To find out more information
about smart pointers and the {\tt SmartPtr} implementation used in
\Ipopt, see Appendix \ref{app.smart_ptr}.

Create the file {\tt MyExample.cpp} in the MyExample directory.
Include {\tt HS071\_NLP.hpp} and {\tt IpIpoptApplication.hpp}, tell
the compiler to use the {\tt Ipopt} namespace, and implement the {\tt
  main} function.
\begin{footnotesize}
\begin{verbatim}
#include "IpIpoptApplication.hpp"
#include "hs071_nlp.hpp"

using namespace Ipopt;

int main(int argv, char* argc[])
{
  // Create a new instance of your nlp 
  //  (use a SmartPtr, not raw)
  SmartPtr<TNLP> mynlp = new HS071_NLP();

  // Create a new instance of IpoptApplication
  //  (use a SmartPtr, not raw)
  SmartPtr<IpoptApplication> app = new IpoptApplication();

  // Change some options
  app->Options()->SetNumericValue("tol", 1e-9);
  app->Options()->SetStringValue("mu_strategy", "adaptive");

  // Ask Ipopt to solve the problem
  ApplicationReturnStatus status = app->OptimizeTNLP(mynlp);

  if (status == Solve_Succeeded) {
    printf("\n\n*** The problem solved!\n");
  }
  else {
    printf("\n\n*** The problem FAILED!\n");
  }

  // As the SmartPtrs go out of scope, the reference count
  // will be decremented and the objects will automatically 
  // be deleted.

  return (int) status;
}
\end{verbatim} 
\end{footnotesize}

The first line of code in {\tt main} creates an instance of {\tt
  HS071\_NLP}. We then create an instance of the \Ipopt\ solver, {\tt
  IpoptApplication}. The call to {\tt app->OptimizeTNLP(...)} will run
\Ipopt\ and try to solve the problem. By default, \Ipopt\ will write
to its progress to the console, and return the {\tt SolverReturn}
status.

\subsubsection{Compiling and Testing the Example}
Our next task is to compile and test the code. If you are familiar
with the compiler and linker used on your system, you can build the
code, including the \Ipopt\ library {\tt libipopt.a} (and other
necessary libraries).  If you are using Linux/UNIX, then a sample
makefile exists already that was created by configure. Copy {\tt
  Examples/hs071\_cpp/Makefile} into your {\tt MyExample} directory.
This makefile was created for the {\tt hs071\_cpp} code, but it can be
easily modified for your example problem. Edit the file, making the
following changes,

\begin{itemize}
\item change the {\tt EXE} variable \\
{\tt EXE = my\_example}
\item change the {\tt OBJS} variable \\
{\tt OBJS = HS071\_NLP.o MyExample.o}
\end{itemize}
and the problem should compile easily with, \\
{\tt \$ make}
Now run the executable,\\ 
{\tt \$ ./my\_example}
and you should see output resembling the following,
\begin{footnotesize}
\begin{verbatim}
Total number of variables............................:        4
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        4
                     variables with only upper bounds:        0
Total number of equality constraints.................:        1
Total number of inequality constraints...............:        1
        inequality constraints with only lower bounds:        1
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0
 
 iter     objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
    0   1.7159878e+01 2.01e-02 5.20e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0 y
    1   1.7146308e+01 1.63e-01 1.47e-01  -1.0 1.15e-01    -  9.86e-01 1.00e+00f  1
    2   1.7065508e+01 3.10e-02 8.47e-02  -1.7 1.99e-01    -  9.54e-01 1.00e+00h  1 Nhj
    3   1.7002626e+01 4.10e-02 4.81e-03  -2.5 5.52e-02    -  1.00e+00 1.00e+00h  1
    4   1.7019082e+01 1.20e-03 1.81e-04  -2.5 1.10e-02    -  1.00e+00 1.00e+00h  1
    5   1.7014253e+01 1.80e-04 4.87e-05  -3.8 4.86e-03    -  1.00e+00 1.00e+00h  1
    6   1.7014020e+01 9.25e-07 2.15e-07  -5.7 2.76e-04    -  1.00e+00 1.00e+00h  1
    7   1.7014017e+01 1.01e-10 2.60e-11  -8.6 3.32e-06    -  1.00e+00 1.00e+00h  1
 
Number of Iterations....: 7
 
                                   (scaled)                 (unscaled)
Objective...............:   1.7014017145177885e+01    1.7014017145177885e+01
Dual infeasibility......:   2.5980210027546616e-11    2.5980210027546616e-11
Constraint violation....:   1.8175683180743363e-11    1.8175683180743363e-11
Complementarity.........:   2.5282956951655172e-09    2.5282956951655172e-09
Overall NLP error.......:   2.5282956951655172e-09    2.5282956951655172e-09
 
 
Number of objective function evaluations             = 8
Number of objective gradient evaluations             = 8
Number of equality constraint evaluations            = 8
Number of inequality constraint evaluations          = 8
Number of equality constraint Jacobian evaluations   = 8
Number of inequality constraint Jacobian evaluations = 8
Number of Lagrangian Hessian evaluations             = 9
 
EXIT: Optimal Solution Found.
 
 
Solution of the primal variables, x
x[0] = 1
x[1] = 4.743
x[2] = 3.82115
x[3] = 1.37941
 
 
Solution of the bound multipliers, z_L and z_U
z_L[0] = 1.08787
z_L[1] = 6.69317e-10
z_L[2] = 8.8877e-10
z_L[3] = 6.57011e-09
z_U[0] = 6.26262e-10
z_U[1] = 9.78906e-09
z_U[2] = 2.12283e-09
z_U[3] = 6.92528e-10
 
 
Objective value
f(x*) = 17.014
 
 
*** The problem solved!
\end{verbatim}
\end{footnotesize}

This completes the basic C++ tutorial, but see Section
\ref{sec.output} which explains the standard console output of \Ipopt
and Section \ref{sec.options} for information about the use of options
to customize the behavior of \Ipopt.

\subsection{The C Interface}\label{sec.cinterface}
The C interface for \Ipopt\ is declared in the header file {\tt
  IpStdCInterface.h}, which is found in\\
\texttt{\$IPOPTDIR/include/ipopt} (or in
\texttt{\$PREFIX/include/ipopt} if the switch
\verb|--prefix=$PREFIX| was used for {\tt configure}); while
reading this section, it will be helpful to have a look at this file.

In order to solve an optimization problem with the C interface, one
has to create an {\tt IpoptProblem}\footnote{{\tt IpoptProblem} is a
  pointer to a C structure; you should not access this structure
  directly, only through the functions provided in the C interface.}
with the function {\tt CreateIpoptProblem}, which later has to be
passed to the {\tt IpoptSolve} function.

The {\tt IpoptProblem} created by {\tt CreateIpoptProblem} contains
the problem dimensions, the variable and constraint bounds, and the
function pointers for callbacks that will be used to evaluate the NLP
problem functions and their derivatives (see also the discussion of
the C++ methods {\tt get\_nlp\_info} and {\tt get\_bounds\_info} in
Section~\ref{sec.cpp_problem} for information about the arguments of
{\tt CreateIpoptProblem}).

The prototypes for the callback functions, {\tt Eval\_F\_CB}, {\tt
  Eval\_Grad\_F\_CB}, etc., are defined in the header file {\tt
  IpStdCInterface.h}.  Their arguments correspond one-to-one to the
arguments for the C++ methods discussed in
Section~\ref{sec.cpp_problem}; for example, for the meaning of $\tt
n$, $\tt x$, $\tt new\_x$, $\tt obj\_value$ in the declaration of {\tt
  Eval\_F\_CB} see the discussion of ``{\tt eval\_f}''.  The callback
functions should return {\tt TRUE}, unless there was a problem doing
the requested function/derivative evaluation at the given point {\tt
  x} (then it should return {\tt FALSE}.

Note the additional argument of type {\tt UserDataPtr} in the callback
functions.  This pointer argument is available for you to communicate
information between the main program that calls {\tt IpoptSolve} and
any of the callback functions.  This pointer is simply passed
unmodified by \Ipopt\ among those functions.  For example, you can
use this to pass constants that define the optimization problem and
are computed before the optimization in the main C program to the
callback functions.

After an {\tt IpoptProblem} has been created, you can set algorithmic
options for \Ipopt\ (see Section~\ref{sec.options}) using the {\tt
  AddIpopt*Option} functions.  Finally, the \Ipopt\ algorithm is
called with {\tt IpoptSolve}, giving \Ipopt\ the {\tt IpoptProblem},
the starting point, and arrays to store the solution values (primal
and dual variables), if desired.  Finally, after everything is done,
you should call {\tt FreeIpoptProblem} to release internal memory that
is still allocated inside \Ipopt.

In the remainder of this section we discuss how the example problem
(\ref{eq:ex_obj})--(\ref{eq:ex_bounds}) can be solved using the C
interface.  A completed version of this example can be found in {\tt
  Examples/hs071\_c}.

% We first create the necessary callback
% functions for evaluating the NLP. As just discussed, the \Ipopt\ C
% interface required callbacks to evaluate the objective value,
% constraints, gradient of the objective, Jacobian of the constraints,
% and the Hessian of the Lagrangian.  These callbacks are implemented
% using function pointers.  Have a look at the C++ implementation for
% {\tt eval\_f}, {\tt eval\_g}, {\tt eval\_grad\_f}, {\tt eval\_jac\_g},
% and {\tt eval\_h} in Section \ref{sec.cpp_problem}. The C
% implementations have somewhat different prototypes, but are
% implemented almost identically to the C++ code.

\vspace{\baselineskip}

In order to implement the example problem on your own, create a new
directory {\tt MyCExample} and create a new file, {\tt
  hs071\_c.c}.  Here, include the interface header file {\tt
  IpStdCInterface.h}, along with other necessary header files, such as
{\tt stdlib.h} and {\tt assert.h}.  Add the prototypes and
implementations for the five callback functions.  Have a look at the
C++ implementation for {\tt eval\_f}, {\tt eval\_g}, {\tt
  eval\_grad\_f}, {\tt eval\_jac\_g}, and {\tt eval\_h} in Section
\ref{sec.cpp_problem}. The C implementations have somewhat different
prototypes, but are implemented almost identically to the C++ code.
See the completed example in {\tt Examples/hs071\_c/hs071\_c.c} if you
are not sure how to do this.

We now need to implement the {\tt main} function, create the {\tt
  IpoptProblem}, set options, and call {\tt IpoptSolve}. The {\tt
  CreateIpoptProblem} function requires the problem dimensions, the
variable and constraint bounds, and the function pointers to the
callback routines. The {\tt IpoptSolve} function requires the {\tt
  IpoptProblem}, the starting point, and allocated arrays for the
solution.  The {\tt main} function from the example is shown next, and
discussed below.

%in Figure~\ref{fig:cexample-main}.
%\begin{figure}
%  \centering
\begin{footnotesize}
\begin{verbatim}
int main()
{
  Index n=-1;                          /* number of variables */
  Index m=-1;                          /* number of constraints */
  Number* x_L = NULL;                  /* lower bounds on x */
  Number* x_U = NULL;                  /* upper bounds on x */
  Number* g_L = NULL;                  /* lower bounds on g */
  Number* g_U = NULL;                  /* upper bounds on g */
  IpoptProblem nlp = NULL;             /* IpoptProblem */
  enum ApplicationReturnStatus status; /* Solve return code */
  Number* x = NULL;                    /* starting point and solution vector */
  Number* mult_x_L = NULL;             /* lower bound multipliers 
					  at the solution */
  Number* mult_x_U = NULL;             /* upper bound multipliers 
					  at the solution */
  Number obj;                          /* objective value */
  Index i;                             /* generic counter */
  
  /* set the number of variables and allocate space for the bounds */
  n=4;
  x_L = (Number*)malloc(sizeof(Number)*n);
  x_U = (Number*)malloc(sizeof(Number)*n);
  /* set the values for the variable bounds */
  for (i=0; i<n; i++) {
    x_L[i] = 1.0;
    x_U[i] = 5.0;
  }

  /* set the number of constraints and allocate space for the bounds */
  m=2;
  g_L = (Number*)malloc(sizeof(Number)*m);
  g_U = (Number*)malloc(sizeof(Number)*m);
  /* set the values of the constraint bounds */
  g_L[0] = 25; g_U[0] = 2e19;
  g_L[1] = 40; g_U[1] = 40;

  /* create the IpoptProblem */
  nlp = CreateIpoptProblem(n, x_L, x_U, m, g_L, g_U, 8, 10, 0, 
			   &eval_f, &eval_g, &eval_grad_f, 
			   &eval_jac_g, &eval_h);
  
  /* We can free the memory now - the values for the bounds have been
     copied internally in CreateIpoptProblem */
  free(x_L);
  free(x_U);
  free(g_L);
  free(g_U);

  /* set some options */
  AddIpoptNumOption(nlp, "tol", 1e-9);
  AddIpoptStrOption(nlp, "mu_strategy", "adaptive");

  /* allocate space for the initial point and set the values */
  x = (Number*)malloc(sizeof(Number)*n);
  x[0] = 1.0;
  x[1] = 5.0;
  x[2] = 5.0;
  x[3] = 1.0;

  /* allocate space to store the bound multipliers at the solution */
  mult_x_L = (Number*)malloc(sizeof(Number)*n);
  mult_x_U = (Number*)malloc(sizeof(Number)*n);

  /* solve the problem */
  status = IpoptSolve(nlp, x, NULL, &obj, NULL, mult_x_L, mult_x_U, NULL);

  if (status == Solve_Succeeded) {
    printf("\n\nSolution of the primal variables, x\n");
    for (i=0; i<n; i++) {
      printf("x[%d] = %e\n", i, x[i]); 
    }

    printf("\n\nSolution of the bound multipliers, z_L and z_U\n");
    for (i=0; i<n; i++) {
      printf("z_L[%d] = %e\n", i, mult_x_L[i]); 
    }
    for (i=0; i<n; i++) {
      printf("z_U[%d] = %e\n", i, mult_x_U[i]); 
    }

    printf("\n\nObjective value\n");
    printf("f(x*) = %e\n", obj); 
  }
 
  /* free allocated memory */
  FreeIpoptProblem(nlp);
  free(x);
  free(mult_x_L);
  free(mult_x_U);

  return 0;
}
\end{verbatim}
\end{footnotesize}
%  \caption{{\tt main} function for C example}
%  \label{fig:cexample-main}
%\end{figure}

Here, we declare all the necessary variables and set the dimensions of
the problem.  The problem has 4 variables, so we set {\tt n} and
allocate space for the variable bounds (don't forget to call {\tt
  free} for each of your {\tt malloc} calls before the end of the
program). We then set the values for the variable bounds.

The problem has 2 constraints, so we set {\tt m} and allocate space
for the constraint bounds. The first constraint has a lower bound of
$25$ and no upper bound.  Here we set the upper bound to
\texttt{2e19}. \Ipopt\ interprets any number greater than
\texttt{nlp\_upper\_bound\_inf} as infinity. The default value of
\texttt{nlp\_lower\_bound\_inf} and \texttt{nlp\_upper\_bound\_inf} is
\texttt{-1e19} and \texttt{1e19}, respectively, and can be changed
through \Ipopt\ options.  The second constraint is an equality, so we
set both the upper and the lower bound to 40.

We next create an instance of the {\tt IpoptProblem} by calling {\tt
CreateIpoptProblem}, giving it the problem dimensions and the variable
and constraint bounds. The arguments {\tt nele\_jac} and {\tt
nele\_hess} are the number of elements in Jacobian and the Hessian,
respectively. See Appendix~\ref{app.triplet} for a description of the
sparse matrix format. The {\tt index\_style} argument specifies whether
we want to use C style indexing for the row and column indices of the
matrices or Fortran style indexing. Here, we set it to {\tt 0} to
indicate C style.  We also include the references to each of our
callback functions. \Ipopt\ uses these function pointers to ask for
evaluation of the NLP when required.

After freeing the bound arrays that are no longer required, the next
two lines illustrate how you can change the value of options through
the interface.  \Ipopt\ options can also be changed by creating a {\tt
PARAMS.DAT} file (see Section~\ref{sec.options}). We next allocate
space for the initial point and set the values as given in the problem
definition.

The call to {\tt IpoptSolve} can provide us with information about the
solution, but most of this is optional. Here, we want values for the
bound multipliers at the solution and we allocate space for these.

We can now make the call to {\tt IpoptSolve} and find the solution of
the problem. We pass in the {\tt IpoptProblem}, the starting point
{\tt x} (\Ipopt\ will use this array to return the solution as well).
The next 5 arguments are pointers so \Ipopt\ can fill in values at the
solution.  If these pointers are set to {\tt NULL}, \Ipopt\ will
ignore that entry.  For example, here, we do not want the constraint
residuals at the solution or the equality multipliers, so we set those
entries to {\tt NULL}. We do want the value of the objective, and the
multipliers for the variable bounds. The last argument is a {\tt
  void*} for user data. Any pointer you give here will also be passed
to you in the callback functions.

The return code is an ApplicationReturnStatus enumeration, see the
header file {\tt ReturnCodes\_inc.h} which is installed along {\tt
  IpStdCInterface.h} in the \Ipopt\ include directory.

After the problem has solved, we check the status and print the
solution if successful. Finally, we free the {\tt IpoptProblem} and
the remaining memory, and return from {\tt main}.

\subsection{The Fortran Interface}

The Fortran interface is essentially a wrapper of the C interface
discussed in Section~\ref{sec.cinterface}.  The way to hook up \Ipopt\
in a Fortran program is very similar to how it is done for the C
interface, and the functions of the Fortran interface correspond
one-to-one to the those of the C interface, including their arguments.
You can find an implementation of the example problem
(\ref{eq:ex_obj})--(\ref{eq:ex_bounds}) in {\tt
  \$IPOPTDIR/Examples/hs071\_f}.

The only special things to consider are:
\begin{itemize}
\item The return value of the function {\tt IPCREATE} is of an {\tt
    INTEGER} type that must be large enough to capture a pointer
  on the particular machine.  This means, that you have to declare
  the ``handle'' for the IpoptProblem as {\tt INTEGER*8} if your
  program is compiled in 64-bit mode.  All other {\tt INTEGER}-type
  variables must be of the regular type.
\item For the call of {\tt IPSOLVE} (which is the function that is to
  be called to run \Ipopt), all arrays, including those for the dual
  variables, must be given (in contrast to the C interface).  The
  return value {\tt IERR} of this function indicates the outcome of
  the optimization (see the include file {\tt IpReturnCodes.inc} in
  the \Ipopt\ include directory.
\item The return {\tt IERR} value of the remaining functions is zero,
  unless there was a problem during execution of the function call.
\item The callback functions ({\tt EV\_*} in the example) include the
  arguments {\tt IDAT} and {\tt DAT}, which are {\tt INTEGER} and {\tt
    DOUBLE PRECISION} arrays that are passed unmodified between the
  main program calling {\tt IPSOLVE} and the evaluation subroutines
  {\tt EV\_*} (similarly to {\tt UserDataPtr} arguments in the C
  interface).  Those can be used to pass ``private'' data between
  the user-provided Fortran subroutines.

  The last argument of the {\tt EV\_*} subroutines, {\tt IERR}, is to
  be set to 0 by the users on return, unless there was a problem
  during the evaluation of the optimization problem
  function/derivative for the given point {\tt X} (then it should
  return a non-zero value).
\end{itemize}


\section{\Ipopt\ Options}\label{sec.options}
Ipopt has many (maybe too many) options that can be adjusted for the
algorithm.  Options are all identified by a string name and their
values can be of one of three types: Number (real), Integer, or
String. Number options are used for things like tolerances, integer
options are used for things like maximum number of iterations, and
string options are used for setting algorithm details, like the NLP
scaling method. Options can be set through code, through the AMPL
interface if you are using AMPL, or by creating a {\tt PARAMS.DAT}
file in the directory you are executing \Ipopt.

The {\tt PARAMS.DAT} file is read line by line and each line should
contain the option name, followed by whitespace, and then the
value. Comments can be included with the {\tt \#} symbol. Don't forget
to ensure you have a newline at the end of the file. For example,
\begin{verbatim}
# This is a comment

# Turn off the NLP scaling
nlp_scaling_method none

# Change the initial barrier parameter
mu_init 1e-2

# Set the max number of iterations
max_iter 500
\end{verbatim}
is a valid {\tt PARAMS.DAT} file.

Options can also be set in code. Have a look at the examples to see
how this is done. 

A subset of \Ipopt\ options are available through AMPL. To set options
through AMPL, use the internal AMPL command {\tt options}.  For
example, \\ 
{\tt options ipopt "nlp\_scaling\_method=none mu\_init=1e-2
max\_iter=500"} \\ 
is a valid options command in AMPL. The most common
options are referenced in Appendix~\ref{app.options_ref}. These are also
the options that are available through AMPL using the {\tt options}
command. To specify other options when using AMPL, you can always
create {\tt PARAMS.DAT}.  Note, the {\tt PARAMS.DAT} file is given
preference when setting options. This way, you can easily override any
options set in a particular executable or AMPL model by specifying new
values in {\tt PARAMS.DAT}.

For a short list of the valid options, see the Appendix
\ref{app.options_ref}. You can print the documentation for all \Ipopt\
options by adding the option, \\ {\tt print\_options\_documentation
yes} \\ and running \Ipopt\ (like the AMPL executable, for
instance). This will output all of the options documentation to the
console.

\section{\Ipopt\ Output}\label{sec.output}
This section describes the standard \Ipopt\ console output with the
default setting for {\tt print\_level}. The output is designed to
provide a quick summary of each iteration as \Ipopt\ solves the problem.

Before \Ipopt\ starts to solve the problem, it displays the problem
statistics (number of variables, etc.). Note that if you have fixed
variables (both upper and lower bounds are equal), \Ipopt\ may remove
these variables from the problem.

Following the problem statistics, \Ipopt\ will begin to solve the
problem and you will see output resembling the following,
\begin{verbatim}
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  1.6109693e+01 1.12e+01 5.28e-01   0.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  1.8029749e+01 9.90e-01 6.62e+01   0.1 2.05e+00    -  2.14e-01 1.00e+00f  1
   2  1.8719906e+01 1.25e-02 9.04e+00  -2.2 5.94e-02   2.0 8.04e-01 1.00e+00h  1
\end{verbatim}
and the columns of output are defined as,
\begin{description}
\item[{\tt iter}:] The current iteration count. This includes regular iterations and
iterations while in restoration phase. If in restoration phase, the letter {\tt r'}
will be appended to the iteration number. 
\item[{\tt objective}:] The unscaled objective value at the current point. In restoration, this value remains the unscaled objective value for the original problem.
\item[{\tt inf\_pr}:] The scaled primal infeasibility at the current point. In restoration, this value is the primal infeasibility of the original problem at the current point.
\item[{\tt inf\_du}:] The scaled dual infeasibility at the current point. In restoration, this is the value of the dual infeasibility for the restoration problem.
\item[{\tt lg(mu)}:] $\log_{10}$ of the value of the barrier parameter mu.
\item[{\tt ||d||}:] The infinity norm (max) of the primal step (in x and s). In restoration, this value includes the values of the additional variables, $p$ and $n$.
\item[{\tt lg(rg)}:] $\log_{10}$ of the value of the regularization term for the Hessian of the Lagrangian in the augmented system.
\item[{\tt alpha\_du}:] The stepsize for the dual variables.
\item[{\tt alpha\_pr}:] The stepsize for the primal variables.
\item[{\tt ls}:] The number of backtracking line search steps.
\end{description}

When the algorithm is complete, \Ipopt\ will output a message to the
screen based on the return status of the call to {\tt Optimize}. The following
is a list of the possible return codes, their corresponding output message
to the console, and a brief description.
\begin{description}
\item[{\tt Solve\_Succeeded}:] $\;$ \\
  Console Message: {\tt EXIT: Optimal Solution Found.} \\
  This message indicates that \Ipopt\ found a (locally) optimal point
  within the desired tolerances.
\item[{\tt Solved\_To\_Acceptable\_Level}:]  $\;$ \\
  Console Message: {\tt EXIT: Solved To Acceptable Level.} \\
  This indicates that was not converged to the desired tolerances, but
  was converged to an acceptable level as specified by {\tt
    acceptable-*} options. This may happen if the desired tolerances
  are too small for the current problem.
\item[{\tt Infeasible\_Problem\_Detected}:]  $\;$ \\
  Console Message: {\tt EXIT: Converged to a point of
    local infeasibility. Problem may be infeasible.} \\
  The restoration phase converged to a point that is a minimizer for
  the constraint violation (in the $\ell_1$-norm), but is not feasible
  for the original problem. This indicates that the problem may be
  infeasible (or at least that the algorithm is stuck at a locally
  infeasible point).  The returned point (the minimizer of the
  constraint violation) might help you to find which constraint is
  causing the problem.  If you believe that the NLP is feasible,
  it might help to start the optimization from a different point.
\item[{\tt Search\_Direction\_Becomes\_Too\_Small}:]  $\;$ \\
  Console Message: {\tt EXIT: Search Direction is becoming Too Small.} \\
  This indicates that \Ipopt\ is calculating very small step sizes and
  making very little progress.  This could happen if the problem has
  been solved to the best numerical accuracy possible given the
  current scaling.
\item[{\tt Maximum\_Iterations\_Exceeded}:]  $\;$ \\
  Console Message: {\tt EXIT: Maximum Number of Iterations Exceeded.} \\
  This indicates that \Ipopt\ has exceeded the maximum number of
  iterations as specified by the option {\tt max\_iter}.
\item[{\tt Restoration\_Failed}:]  $\;$ \\
  Console Message: {\tt EXIT: Restoration Failed!} \\
  This indicates that the restoration phase failed to find a feasible
  point that was acceptable to the filter line search for the original
  problem. This could happen if the problem is highly degenerate or if
  your NLP provides incorrect derivative information.
\item[{\tt Invalid\_Option}:]  $\;$ \\
  Console Message: (details about the particular error
  will be output to the console) \\
  This indicates that there was some problem specifying the options.
  See the specific message for details.
\item[{\tt Not\_Enough\_Degrees\_Of\_Freedom}:]  $\;$ \\
  Console Message: {\tt EXIT: Problem has too few degrees of freedom.} \\
  This indicates that your problem, as specified, has too few degrees
  of freedom. This can happen if you have too many equality
  constraints, or if you fix too many variables (\Ipopt\ removes fixed
  variables).
\item[{\tt Invalid\_Problem\_Definition}:]  $\;$ \\
  Console Message: (no console message, this is a return code for the
  C and Fortran interfaces only.) \\
  This indicates that there was an exception of some sort when
  building the {\tt IpoptProblem} structure in the C or Fortran
  interface. Likely there is an error in your model or the {\tt main}
  routine.
\item[{\tt Unrecoverable\_Exception}:]  $\;$ \\
  Console Message: (details about the particular error
  will be output to the console) \\
  This indicates that \Ipopt\ has thrown an exception that does not
  have an internal return code. See the specific message for details.
\item[{\tt NonIpopt\_Exception\_Thrown}:]  $\;$ \\
  Console Message: {\tt Unknown Exception caught in Ipopt} \\
  An unknown exception was caught in \Ipopt. This exception could have
  originated from your model or any linked in third party code.
\item[{\tt Insufficient\_Memory}:]  $\;$ \\
  Console Message: {\tt EXIT: Not enough memory.} \\
  An error occurred while trying to allocate memory. The problem may
  be too large for your current memory and swap configuration.
\item[{\tt Internal\_Error}:]  $\;$ \\
  Console Message: {\tt EXIT: INTERNAL ERROR: Unknown SolverReturn
    value - Notify IPOPT Authors.} \\
  An unknown internal error has occurred. Please notify the authors of
  \Ipopt.

\end{description}

%\bibliographystyle{plain}
%\bibliography{/home/andreasw/tex/andreas}
\input{documentation.bbl}

\appendix
\newpage
\section{Triplet Format for Sparse Matrices}\label{app.triplet}
\Ipopt\ was designed for optimizing large sparse nonlinear programs. 
Because of problem sparsity, the required matrices (like the Jacobian or Hessian) are not stored as traditional dense matrices, but rather in a sparse matrix format. For the tutorials in this document, we use the triplet format. 
Consider the matrix,
\begin{equation}
\label{eqn.ex_matrix}
\left[
\begin{array}{ccccccc}
1.1     & 0             & 0             & 0             & 0             & 0             & 0.5 \\
0       & 1.9   & 0             & 0             & 0             & 0             & 0.5 \\
0       & 0             & 2.6   & 0             & 0             & 0             & 0.5 \\
0       & 0             & 7.8   & 0.6   & 0             & 0             & 0    \\
0       & 0             & 0             & 1.5   & 2.7   & 0             & 0     \\
1.6     & 0             & 0             & 0             & 0.4   & 0             & 0     \\
0       & 0             & 0             & 0             & 0             & 0.9   & 1.7 \\
\end{array}
\right]
\end{equation}

A standard dense matrix representation would need to store $7 \cdot
7{=} 49$ floating point numbers, where many entries would be zero. In
triplet format, however, only the nonzero entries are stored. The
triplet format records the row number, the column number, and the
value of all nonzero entries in the matrix. For the matrix above, this
means storing $14$ integers for the rows, $14$ integers for the
columns, and $14$ floating point numbers for the values. While this
does not seem like a huge space savings over the $49$ floating point
numbers stored in the dense representation, for larger matrices, the
space savings are very dramatic\footnote{For an $n \times n$ matrix,
the dense representation grows with the the square of $n$, while the
sparse representation grows linearly in the number of nonzeros.}

The option {\tt index\_style} in {\tt get\_nlp\_info} tells \Ipopt\ if
you prefer to use C style indexing (0-based) for the row and column
indices or Fortran style (1-based). Tables \ref{tab.fortran_triplet} and 
\ref{tab.c_triplet} below show the triplet
format for both indexing styles, using the example matrix (\ref{eqn.ex_matrix}).

\begin{footnotesize}
\begin{table}[ht]%[!h]
\begin{center}
\caption{Triplet Format of Matrix (\ref{eqn.ex_matrix}) 
with {\tt index\_style=FORTRAN\_STYLE}}
\label{tab.fortran_triplet}
\begin{tabular}{c c c}
row     		&       col     	&       value 			    \\
\hline
{\tt iRow[0] = 1}       &       {\tt jCol[0] = 1}       & {\tt values[0] = 1.1}     \\
{\tt iRow[1] = 1}       &       {\tt jCol[1] = 7}       & {\tt values[1] = 0.5}     \\
{\tt iRow[2] = 2}       &       {\tt jCol[2] = 2}       & {\tt values[2] = 1.9}     \\
{\tt iRow[3] = 2}       &       {\tt jCol[3] = 7}       & {\tt values[3] = 0.5}     \\
{\tt iRow[4] = 3}       &       {\tt jCol[4] = 3}       & {\tt values[4] = 2.6}     \\
{\tt iRow[5] = 3}       &       {\tt jCol[5] = 7}       & {\tt values[5] = 0.5}     \\
{\tt iRow[6] = 4}       &       {\tt jCol[6] = 3}       & {\tt values[6] = 7.8}     \\
{\tt iRow[7] = 4}       &       {\tt jCol[7] = 4}       & {\tt values[7] = 0.6}     \\
{\tt iRow[8] = 5}       &       {\tt jCol[8] = 4}       & {\tt values[8] = 1.5}     \\
{\tt iRow[9] = 5}       &       {\tt jCol[9] = 5}       & {\tt values[9] = 2.7}     \\
{\tt iRow[10] = 6}      &       {\tt jCol[10] = 1}      & {\tt values[10] = 1.6}     \\
{\tt iRow[11] = 6}      &       {\tt jCol[11] = 5}      & {\tt values[11] = 0.4}     \\
{\tt iRow[12] = 7}      &       {\tt jCol[12] = 6}      & {\tt values[12] = 0.9}     \\
{\tt iRow[13] = 7}      &       {\tt jCol[13] = 7}      & {\tt values[13] = 1.7}
\end{tabular}
\end{center}
\end{table}
\begin{table}[ht]%[!h]
\begin{center}
\caption{Triplet Format of Matrix (\ref{eqn.ex_matrix}) 
with {\tt index\_style=C\_STYLE}}
\label{tab.c_triplet}
\begin{tabular}{c c c}
row     		&       col     	&       value 			    \\
\hline
{\tt iRow[0] = 0}       &       {\tt jCol[0] = 0}       & {\tt values[0] = 1.1}     \\
{\tt iRow[1] = 0}       &       {\tt jCol[1] = 6}       & {\tt values[1] = 0.5}     \\
{\tt iRow[2] = 1}       &       {\tt jCol[2] = 1}       & {\tt values[2] = 1.9}     \\
{\tt iRow[3] = 1}       &       {\tt jCol[3] = 6}       & {\tt values[3] = 0.5}     \\
{\tt iRow[4] = 2}       &       {\tt jCol[4] = 2}       & {\tt values[4] = 2.6}     \\
{\tt iRow[5] = 2}       &       {\tt jCol[5] = 6}       & {\tt values[5] = 0.5}     \\
{\tt iRow[6] = 3}       &       {\tt jCol[6] = 2}       & {\tt values[6] = 7.8}     \\
{\tt iRow[7] = 3}       &       {\tt jCol[7] = 3}       & {\tt values[7] = 0.6}     \\
{\tt iRow[8] = 4}       &       {\tt jCol[8] = 3}       & {\tt values[8] = 1.5}     \\
{\tt iRow[9] = 4}       &       {\tt jCol[9] = 4}       & {\tt values[9] = 2.7}     \\
{\tt iRow[10] = 5}      &       {\tt jCol[10] = 0}      & {\tt values[10] = 1.6}     \\
{\tt iRow[11] = 5}      &       {\tt jCol[11] = 4}      & {\tt values[11] = 0.4}     \\
{\tt iRow[12] = 6}      &       {\tt jCol[12] = 5}      & {\tt values[12] = 0.9}     \\
{\tt iRow[13] = 6}      &       {\tt jCol[13] = 6}      & {\tt values[13] = 1.7}
\end{tabular}
\end{center}
\end{table}
\end{footnotesize}
The individual elements of the matrix can be listed in any order, and
if there are multiple items for the same nonzero position, the values
provided for those positions are added.

The Hessian of the Lagrangian is a symmetric matrix. In the case of a
symmetric matrix, you only need to specify the lower left corner. For
example, given the matrix,
\begin{equation}
\label{eqn.ex_sym_matrix}
\left[
\begin{array}{ccccccc}
1.0	& 0	& 3.0	& 0	& 2.0 	\\
0	& 1.1	& 0	& 0	& 5.0	\\
3.0	& 0	& 1.2	& 6.0	& 0	\\
0	& 0	& 6.0	& 1.3	& 9.0	\\
2.0	& 5.0	& 0	& 9.0	& 1.4
\end{array}
\right]
\end{equation}
the triplet format is shown in Tables \ref{tab.sym_fortran_triplet}
and \ref{tab.sym_c_triplet}.
\begin{footnotesize}
\begin{table}[ht]%[!h]
\begin{center}
\caption{Triplet Format of Matrix (\ref{eqn.ex_matrix}) 
with {\tt index\_style=FORTRAN\_STYLE}}
\label{tab.sym_fortran_triplet}
\begin{tabular}{c c c}
row     		&       col     	&       value 			    \\
\hline
{\tt iRow[0] = 1}       &       {\tt jCol[0] = 1}       & {\tt values[0] = 1.0}     \\
{\tt iRow[1] = 2}       &       {\tt jCol[1] = 1}       & {\tt values[1] = 1.1}     \\
{\tt iRow[2] = 3}       &       {\tt jCol[2] = 1}       & {\tt values[2] = 3.0}     \\
{\tt iRow[3] = 3}       &       {\tt jCol[3] = 3}       & {\tt values[3] = 1.2}     \\
{\tt iRow[4] = 4}       &       {\tt jCol[4] = 3}       & {\tt values[4] = 6.0}     \\
{\tt iRow[5] = 4}       &       {\tt jCol[5] = 4}       & {\tt values[5] = 1.3}     \\
{\tt iRow[6] = 5}       &       {\tt jCol[6] = 1}       & {\tt values[6] = 2.0}     \\
{\tt iRow[7] = 5}       &       {\tt jCol[7] = 2}       & {\tt values[7] = 5.0}     \\
{\tt iRow[8] = 5}       &       {\tt jCol[8] = 4}       & {\tt values[8] = 9.0}     \\
{\tt iRow[9] = 5}       &       {\tt jCol[9] = 5}       & {\tt values[9] = 1.4}
\end{tabular}
\end{center}
\end{table}
\begin{table}[ht]%[!h]
\begin{center}
\caption{Triplet Format of Matrix (\ref{eqn.ex_matrix}) 
with {\tt index\_style=C\_STYLE}}
\label{tab.sym_c_triplet}
\begin{tabular}{c c c}
row     		&       col     	&       value 			    \\
\hline
{\tt iRow[0] = 0}       &       {\tt jCol[0] = 0}       & {\tt values[0] = 1.0}     \\
{\tt iRow[1] = 1}       &       {\tt jCol[1] = 0}       & {\tt values[1] = 1.1}     \\
{\tt iRow[2] = 2}       &       {\tt jCol[2] = 0}       & {\tt values[2] = 3.0}     \\
{\tt iRow[3] = 2}       &       {\tt jCol[3] = 2}       & {\tt values[3] = 1.2}     \\
{\tt iRow[4] = 3}       &       {\tt jCol[4] = 2}       & {\tt values[4] = 6.0}     \\
{\tt iRow[5] = 3}       &       {\tt jCol[5] = 3}       & {\tt values[5] = 1.3}     \\
{\tt iRow[6] = 4}       &       {\tt jCol[6] = 0}       & {\tt values[6] = 2.0}     \\
{\tt iRow[7] = 4}       &       {\tt jCol[7] = 1}       & {\tt values[7] = 5.0}     \\
{\tt iRow[8] = 4}       &       {\tt jCol[8] = 3}       & {\tt values[8] = 9.0}     \\
{\tt iRow[9] = 4}       &       {\tt jCol[9] = 4}       & {\tt values[9] = 1.4}
\end{tabular}
\end{center}
\end{table}
\end{footnotesize}
\newpage
\section{The Smart Pointer Implementation: {\tt SmartPtr<T>}} \label{app.smart_ptr}

The {\tt SmartPtr} class is described in {\tt IpSmartPtr.hpp}. It is a
template class that takes care of deleting objects for us so we need
not be concerned about memory leaks. Instead of pointing to an object
with a raw C++ pointer (e.g. {\tt HS071\_NLP*}), we use a {\tt
  SmartPtr}.  Every time a {\tt SmartPtr} is set to reference an
object, it increments a counter in that object (see the {\tt
  ReferencedObject} base class if you are interested). If a {\tt
  SmartPtr} is done with the object, either by leaving scope or being
set to point to another object, the counter is decremented. When the
count of the object goes to zero, the object is automatically deleted.
{\tt SmartPtr}'s are very simple, just use them as you would a
standard pointer.

It is very important to use {\tt SmartPtr}'s instead of raw pointers
when passing objects to \Ipopt. Internally, \Ipopt\ uses smart
pointers for referencing objects. If you use a raw pointer in your
executable, the object's counter will NOT get incremented. Then, when
\Ipopt\ uses smart pointers inside its own code, the counter will get
incremented. However, before \Ipopt\ returns control to your code, it
will decrement as many times as it incremented and the counter will
return to zero. Therefore, \Ipopt\ will delete the object. When
control returns to you, you now have a raw pointer that points to a
deleted object.

This might sound difficult to anyone not familiar with the use of
smart pointers, but just follow one simple rule; always use a SmartPtr
when creating or passing an \Ipopt\ object.

\newpage
\section{Options Reference} \label{app.options_ref}
Options can be set using {\tt PARAMS.DAT}, through your own code, or through the 
AMPL {\tt options} command. See Section \ref{sec.options} for an explanation of
how to use these commands.
Shown here is a short list of the most common options for Ipopt. To view
the full list of options, run the ipopt executable with the option,
\begin{verbatim}
print_options_documentation yes
\end{verbatim}

The most common options are:

\input{options.tex}

\newpage
\section{Detailed Installation Information}\label{ExpertInstall}

The configuration script and Makefiles in the \Ipopt\ distribution
have been created using GNU's {\tt autoconf} and {\tt automake}.  They
attempt to automatically adapt the compiler settings etc.\ to the
system they are running on.  We tested a the provided scripts for a
number of different machines, operating systems and compilers, but you
might easily run into a situation where the default setting does not
work, or where you need to change the settings to fit your particular
environment.

In general, you can see the list of options and variables that can be
set for the {\tt configure} script by typing \verb/configure --help/.
Below a few particular options are discussed:

\begin{itemize}
\item The {\tt configure} script tries to determine automatically, if
  you have BLAS already installed on your system (trying a few default
  libraries), and if it does not find them, it makes sure that you
  put the source code in the required place.

  However, you can specify a BLAS library (such as your local ATLAS
  library) explicitly, using the \verb/--with-blas/ flag for {\tt
    configure}.  For example,

  \verb|./configure --with=blas="-L$HOME/lib -latlas"|

  To tell the configure script to compile and use the downloaded BLAS
  source files even if a BLAS library is found on your system, specify
  \verb|--with-blas=BUILD|.

\item Similarly, if you have a precompiled library containing the
  Harwell Subroutines, you can specify its location with the
  \verb|--with-hsl| flag.  And the location of the AMPL solver library
  (with the ASL header files) can be specified with
  \verb|--with-asldir|.

\item If you want to specify that you want to use particular
  compilers, you can do so by adding the variables definitions for
  {\tt CXX}, {\tt CC}, and {\tt F77} to the {\tt ./configure} command
  line, to specify the C++, C, and Fortran compiler, respectively.
  For example,

  {\tt ./configure CXX=g++ CC=gcc F77=g77}

  In order to set the compiler flags, you should use the variables
  {\tt CXXFLAGS}, {\tt CFLAGS}, {\tt FFLAGS}.  Note, that the \Ipopt\
  code uses ``{\tt dynamic\_cast}''.  Therefore it is necessary that
  the C++ code is compiled including RTTI (Run-Time Type Information).
  Some compilers need to be given special flags to do that (e.g.,
  ``{\tt -qrtti=dyna}'' for the AIX {\tt xlC} compiler).

\item If you want to link the \Ipopt\ library with a main program
  written in C or Fortran, the C and Fortran compiler doing the
  linking of the executable needs to be told about the C++ runtime
  libraries.  Unfortunately, the current version of {\tt autoconf}
  does not provide the automatic detection of those libraries.  We
  have hard-coded some default values for some systems and compilers,
  but this might not work all the time.

  If you have problems linking your Fortran or C code with the \Ipopt\
  library {\tt libipopt.a} and the linker complains about missing
  symbols from C++ (e.g., the standard template library), you should
  specify the C++ libraries with the {\tt CXXLIBS} variable.  To find out
  what those libraries are, it is probably helpful to link a C++
  program with verbose compiler output.

  For example, for the Intel compilers on a Linux system, you
  might need to specify something like

  {\tt ./configure CC=icc F77=ifort CXX=icpc $\backslash$\\ \hspace*{14ex} CXXLIBS='-L/usr/lib/gcc-lib/i386-redhat-linux/3.2.3 -lstdc++'}

\item Compilation in 64bit sometimes requires some special
  consideration.  For example, for compilation of 64bit code on AIX,
  we recommend the following configuration

  {\tt ./configure AR='ar -X64' AR\_X='ar -X64 x' $\backslash$\\
    \hspace*{14ex} CC='xlc -q64' F77='xlf -q64' CXX='xlC
    -q64'$\backslash$\\ \hspace*{14ex} CFLAGS='-O3
    -bmaxdata:0x3f0000000'
    $\backslash$\\ \hspace*{14ex} FFLAGS='-O3 -bmaxdata:0x3f0000000' $\backslash$\\
    \hspace*{14ex} CXXFLAGS='-qrtti=dyna -O3 -bmaxdata:0x3f0000000'}

\item To build library/archive files (with the ending {\tt .a})
  including C++ code in some environments, it is necessary to use the
  C++ compiler instead of {\tt ar} to build the archive.  This is for
  example the case for some older compilers on SGI and SUN.  For this,
  the {\tt configure} variables {\tt AR}, {\tt ARFLAGS}, and {\tt
    AR\_X} are provided.  Here, {\tt AR} specifies the command for the
  archiver for creating an archive, and {\tt ARFLAGS} specifies
  additional flags.  {\tt AR\_X} contains the command for extracting
  all files from an archive.  For example, the default setting for SUN
  compilers for our configure script is

  {\tt AR='CC-xar' ARFLAGS='-o' AR\_X='ar x'}

\item It is possible to compile the \Ipopt\ library in a debug
  configuration, by specifying \verb|--enable-debug|.  Then the
  compilers will use the debug flags (unless the compilation flag
  variables are overwritten in the command line), and additional debug
  checks are compiled into the code.  This usually leads to a
  significant slowdown of the code, but might be helpful when
  debugging something.

\item It is not necessary to produce the binary files in the
  directories where the source files are.  If you want to compile the
  code on different systems on a shared file system, you can keep one
  single copy of the source files in one directory, and the binary
  files for each configuration in separate directories.  For this,
  simply run the configure script in the directory where you want the
  base directory for the \Ipopt\ binary files.  For example:

  {\tt \$ mkdir \$HOME/Ipopt-objects}\\
  {\tt \$ cd \$HOME/Ipopt-objects}\\
  {\tt \$ \$HOME/Ipopt/trunk/configure}

\end{itemize}

\end{document}
